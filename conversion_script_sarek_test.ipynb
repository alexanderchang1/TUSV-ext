{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5e3a04a-2559-44f1-9eb3-0b0f4b0b2da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145818, 13)\n",
      "(1737, 13)\n",
      "(381, 11)\n",
      "(78, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Define global variables\n",
    "cnv_count = 0\n",
    "sv_count = 0\n",
    "snv_count = 0\n",
    "\n",
    "\n",
    "def increment_cnv():\n",
    "    global cnv_count\n",
    "    cnv_count += 1\n",
    "\n",
    "def increment_sv():\n",
    "    global sv_count\n",
    "    sv_count += 1\n",
    "\n",
    "def increment_snv():\n",
    "    global snv_count\n",
    "    snv_count += 1\n",
    "\n",
    "\n",
    "# Take in a list of sample identifiers as a .txt within that variant folder, with an option to auto-generate based on what's in the first folder\n",
    "\n",
    "\n",
    "def convert_chromosome(chrom):\n",
    "    if chrom == 'chrX':\n",
    "        return 23\n",
    "    elif chrom == \"chrY\":\n",
    "        return 24\n",
    "    else:\n",
    "        return int(chrom[3:])\n",
    "\n",
    "\n",
    "def read_sample_list(path):\n",
    "    \"\"\"\n",
    "    Returns a list of samples to compile across Sarek output that has different Strelka, Mutect, Manta and CNVKit output in separate folders.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: a path to a .txt file with the appropriate common folder headers. \n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Function to init the vcf file with the sample name. \n",
    "\n",
    "def init_vcf(output_folder, sample):\n",
    "\n",
    "    \"\"\"\n",
    "    Initializes the vcf output in the appropriate folder,\n",
    "\n",
    "    Parameters:\n",
    "    -------------\n",
    "\n",
    "    output_folder: folder that will have the per-sample.vcf files compiled from various callers, this will be the input for TUSV-ext.\n",
    "    sample: sample name, which will become the filename of the vcf file.\n",
    "    \n",
    "    \"\"\"\n",
    "    output_file_path = os.path.join(output_folder, sample + '.vcf')\n",
    "    \n",
    "    file_vcf = open(output_file_path,'w')\n",
    "    file_vcf.write('##fileformat=VCFv4.2\\n\\\n",
    "##filedate=20211011\\n\\\n",
    "##INFO=<ID=END,Number=1,Type=Integer,Description=\"End position of the variant described in this record\">\\n\\\n",
    "##INFO=<ID=IMPRECISE,Number=0,Type=Flag,Description=\"Imprecise structural variation\">\\n\\\n",
    "##INFO=<ID=MATEID,Number=.,Type=String,Description=\"ID of mate breakends\">\\n\\\n",
    "##INFO=<ID=SVTYPE,Number=1,Type=String,Description=\"Type of structural variant\">\\n\\\n",
    "##FORMAT=<ID=GT,Number=1,Type=Integer,Description=\"Genotype\">\\n\\\n",
    "##FORMAT=<ID=CN,Number=2,Type=Integer,Description=\"Copy number genotype for imprecise events\">\\n\\\n",
    "##FORMAT=<ID=CNADJ,Number=.,Type=Integer,Description=\"Copy number of adjacency\">\\n\\\n",
    "##FORMAT=<ID=BDP,Number=1,Type=Integer,Description=\"Depth of split reads\">\\n\\\n",
    "##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read depth\">\\n\\\n",
    "##ALT=<ID=DEL,Description=\"Deletion\">\\n\\\n",
    "##ALT=<ID=DUP,Description=\"Duplication\">\\n\\\n",
    "##ALT=<ID=INS,Description=\"Insertion of novel sequence\">\\n\\\n",
    "##ALT=<ID=CNV,Description=\"Copy number variable region\">\\n\\\n",
    "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tTUMOR\tNORMAL\\n')\n",
    "\n",
    "    return output_file_path\n",
    "\n",
    "# Function to take in CNA from CNVkit\n",
    "\n",
    "def write_df_to_vcf(df, vcf_file):\n",
    "    \"\"\"\n",
    "    Writes a pandas DataFrame to a VCF file with header already in it.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing the variant data.\n",
    "    - vcf_file (str): Path to the output VCF file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Write the DataFrame to the VCF file\n",
    "    df.to_csv(vcf_file, sep='\\t', mode='a', index=False, header=False)\n",
    "\n",
    "def load_cnvkit_cns(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CNVKit .cns file and loads it into a pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - file_path (str): Path to the CNVKit .cns file.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing the CNVKit .cns data.\n",
    "    \"\"\"\n",
    "    # Read the .cns file into a DataFrame\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    \n",
    "    # Ensure that the columns we need are present\n",
    "    required_columns = ['chromosome', 'start', 'end', 'log2', 'depth']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Required column '{col}' not found in the .cns file.\")\n",
    "    \n",
    "    # Return the DataFrame\n",
    "    return df\n",
    "\n",
    "def cnvkit_to_df(cnvkit_df):\n",
    "    \"\"\"\n",
    "    Converts a CNVKit DataFrame into a VCF-like DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - cnvkit_df (pd.DataFrame): DataFrame containing CNVKit data.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame formatted for VCF output.\n",
    "    \"\"\"\n",
    "    vcf_records = []\n",
    "\n",
    "    \n",
    "    \n",
    "    for idx, row in cnvkit_df.iterrows():\n",
    "        chrom = row['chromosome']\n",
    "        pos = row['start']\n",
    "        id = f'cnv{cnv_count}'\n",
    "        increment_cnv()\n",
    "        ref = '.'\n",
    "        alt = '<CNV>'\n",
    "        qual = '.'\n",
    "        filter = 'PASS'\n",
    "        end = row['end']\n",
    "        info = f'END={end};IMPRECISE'\n",
    "        format_field = 'GT:CN'\n",
    "        tumor_cn = f'1|1:{row[\"log2\"]},{row[\"depth\"]}'\n",
    "        normal_cn = '0|0:1,1'\n",
    "        record = {\n",
    "            '#CHROM': chrom,\n",
    "            'POS': pos,\n",
    "            'ID': id,\n",
    "            'REF': ref,\n",
    "            'ALT': alt,\n",
    "            'QUAL': qual,\n",
    "            'FILTER': filter,\n",
    "            'INFO': info,\n",
    "            'FORMAT': format_field,\n",
    "            'TUMOR': tumor_cn,\n",
    "            'NORMAL': normal_cn\n",
    "        }\n",
    "        vcf_records.append(record)\n",
    "    \n",
    "    vcf_df = pd.DataFrame(vcf_records)\n",
    "    \n",
    "    return vcf_df\n",
    "\n",
    "\n",
    "# Function to take in SNVs from Strelka\n",
    "\n",
    "def read_strelka(input_file_path):\n",
    "    \"\"\"\n",
    "    Function that reads in the file path to the Strelka SNV output, processes it and returns it as a df_SNV.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_file_path = input file for the strelka_snv\n",
    "    \n",
    "    \"\"\"\n",
    "    filtered_lines = []\n",
    "    with gzip.open(input_file_path, 'rt') as file:\n",
    "        for line in file:\n",
    "            if not line.startswith('##'):\n",
    "                filtered_lines.append(line)\n",
    "\n",
    "    filtered_content = ''.join(filtered_lines)\n",
    "    df_snv = pd.read_csv(StringIO(filtered_content), sep='\\t')\n",
    "    df_snv['chr'] = df_snv['#CHROM'].apply(convert_chromosome)\n",
    "    df_snv['data'] = df_snv[list(df_snv.columns)[-2]]\n",
    "\n",
    "    return df_snv\n",
    "\n",
    "def convert_strelka_to_tusv_ext_df(strelka_df, option):\n",
    "\n",
    "    \"\"\"\n",
    "    Converts default read-in SV to a TUSV-ext compatible format.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "\n",
    "    strelka_df = Dataframe from read_strelka function\n",
    "    option = either \"SNV\" or \"INDEL\" for ID labelling.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty list to store the rows of the new DataFrame\n",
    "    tusv_ext_rows = []\n",
    "\n",
    "    print(strelka_df.shape)\n",
    "    strelka_df = strelka_df[strelka_df[\"FILTER\"] == \"PASS\"]\n",
    "    print(strelka_df.shape)\n",
    "    strelka_df.reset_index(inplace=True)\n",
    "\n",
    "    for index, row in strelka_df.iterrows():\n",
    "        chrom = row['#CHROM']\n",
    "        pos = row['POS']\n",
    "        ref = row['REF']\n",
    "        alt = row['ALT']\n",
    "        normal_data = row['NORMAL']\n",
    "        tumor_data = row['TUMOR']\n",
    "        \n",
    "        # Example ID and other static fields for simplicity\n",
    "\n",
    "        if option == \"SNV\":\n",
    "            variant_id = f\"snv{snv_count}\"\n",
    "            increment_snv()\n",
    "        elif option == \"INDEL\":\n",
    "            variant_id = f\"sv{sv_count}\"\n",
    "            increment_sv()\n",
    "        \n",
    "        qual = \".\"\n",
    "        filter_val = row[\"FILTER\"]\n",
    "        info = \".\"\n",
    "        format_val = \"GT:CNADJ\"\n",
    "        \n",
    "        # Extract GT and CNADJ values\n",
    "        normal_gt = \"0|0\"\n",
    "        tumor_gt = \"0|1\"\n",
    "        normal_cnadj = \"0\"\n",
    "        tumor_cnadj = \"0\"\n",
    "        \n",
    "        normal = f\"{normal_gt}:{normal_cnadj}\"\n",
    "        tumor = f\"{tumor_gt}:{tumor_cnadj}\"\n",
    "        \n",
    "        tusv_ext_rows.append([\n",
    "            chrom, pos, variant_id, ref, alt, qual, filter_val, info, format_val, tumor, normal\n",
    "        ])\n",
    "    \n",
    "    # Create a new DataFrame with the appropriate columns\n",
    "    tusv_ext_df = pd.DataFrame(tusv_ext_rows, columns=[\n",
    "        '#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'TUMOR', 'NORMAL'\n",
    "    ])\n",
    "    \n",
    "    return tusv_ext_df\n",
    "\n",
    "\n",
    "\n",
    "# Function to take in large SVs from Manta\n",
    "\n",
    "def read_manta_sv(input_file_path):\n",
    "\n",
    "\n",
    "    filtered_lines = []\n",
    "    with gzip.open(input_file_path, 'rt') as file:\n",
    "        for line in file:\n",
    "            if not line.startswith('##'):\n",
    "                filtered_lines.append(line)\n",
    "\n",
    "    filtered_content = ''.join(filtered_lines)\n",
    "    df_manta_sv = pd.read_csv(StringIO(filtered_content), sep='\\t')\n",
    "    \n",
    "    return df_manta_sv\n",
    "\n",
    "\n",
    "def rewrite_manta_results(df):\n",
    "    new_rows = []\n",
    "\n",
    "    print(df.shape)\n",
    "    df = df[df[\"FILTER\"] == \"PASS\"]\n",
    "    print(df.shape)\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Identify TUMOR and NORMAL columns\n",
    "    tumor_col = next(col for col in df.columns if col.split('-')[-1].startswith('T'))\n",
    "    normal_col = next(col for col in df.columns if col.split('-')[-1].startswith('N'))\n",
    "    \n",
    "    id_counter = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        id_counter += 1\n",
    "        sv_id = f\"sv{sv_count}\"\n",
    "        increment_sv()\n",
    "        \n",
    "        info_dict = dict(item.split('=') for item in row['INFO'].split(';') if '=' in item)\n",
    "        mate_id = info_dict.get('MATEID', '').split(':')[0]\n",
    "        sv_type = info_dict.get('SVTYPE', '')\n",
    "        sv_len = info_dict.get('SVLEN', '')\n",
    "        end = info_dict.get('END', '')\n",
    "        \n",
    "        alt = row['ALT']\n",
    "        if sv_type == 'BND':\n",
    "            match = re.search(r'\\[(.*?)\\[|\\](.*?)\\]', alt)\n",
    "            if match:\n",
    "                chr_pos = match.group(1) or match.group(2)\n",
    "                chr, pos = chr_pos.split(':')\n",
    "                alt = f\"[{chr}:{pos}[\" if '[' in row['ALT'] else f\"]{chr}:{pos}]\"\n",
    "        \n",
    "        # Extract PR and SR from FORMAT field\n",
    "        format_fields = row['FORMAT'].split(':')\n",
    "        tumor_values = row[tumor_col].split(':')\n",
    "        normal_values = row[normal_col].split(':')\n",
    "        \n",
    "        format_dict = dict(zip(format_fields, tumor_values))\n",
    "        pr_tumor = format_dict.get('PR', '0,0')\n",
    "        sr_tumor = format_dict.get('SR', '0,0')\n",
    "        \n",
    "        format_dict = dict(zip(format_fields, normal_values))\n",
    "        pr_normal = format_dict.get('PR', '0,0')\n",
    "        sr_normal = format_dict.get('SR', '0,0')\n",
    "        \n",
    "        new_row = {\n",
    "            '#CHROM': row['#CHROM'],\n",
    "            'POS': row['POS'],\n",
    "            'ID': sv_id,\n",
    "            'REF': row['REF'],\n",
    "            'ALT': alt,\n",
    "            'QUAL': row['QUAL'],\n",
    "            'FILTER': row['FILTER'],\n",
    "            'INFO': f\"MATEID={mate_id};SVTYPE={sv_type};SVLEN={sv_len};END={end}\",\n",
    "            'FORMAT': 'GT:PR:SR',\n",
    "            'TUMOR': f\"{tumor_values[0]}:{pr_tumor}:{sr_tumor}\",\n",
    "            'NORMAL': f\"{normal_values[0]}:{pr_normal}:{sr_normal}\"\n",
    "        }\n",
    "        \n",
    "        new_rows.append(new_row)\n",
    "    \n",
    "    new_df = pd.DataFrame(new_rows, columns=['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'TUMOR', 'NORMAL'])\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    \n",
    "    # Define global variables\n",
    "    cnv_count = 0\n",
    "    sv_count = 0\n",
    "    snv_count = 0\n",
    "    variant_calling_folder = '/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/TUSV-ext/variant_calling'\n",
    "    output_folder = '/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/TUSV-ext/compiled_input/'\n",
    "    sample_name = 'AUR-AER5-TTP2_vs_AUR-AER5-NT2'\n",
    "    strelka_snv_path = os.path.join(variant_calling_folder,'strelka',sample_name,sample_name + '.strelka.somatic_snvs.vcf.gz')\n",
    "    strelka_indel_path = os.path.join(variant_calling_folder,'strelka',sample_name,sample_name + '.strelka.somatic_indels.vcf.gz')\n",
    "    manta_sv_path = os.path.join(variant_calling_folder,'manta',sample_name,sample_name + '.manta.somatic_sv.vcf.gz')\n",
    "    cnvkit_cns_path = os.path.join(variant_calling_folder,'cnvkit',sample_name,sample_name.split('_vs_')[0] + '.cns')\n",
    "\n",
    "\n",
    "\n",
    "    output_file_path = init_vcf(output_folder, sample_name)\n",
    "    \n",
    "    df_snv = read_strelka(strelka_snv_path)\n",
    "    tusv_ext_snv = convert_strelka_to_tusv_ext_df(df_snv, \"SNV\")\n",
    "    write_df_to_vcf(tusv_ext_snv, output_file_path)\n",
    "    \n",
    "    # Commenting out for now as it seems base TUSV-ext can't handle Strelka indels.\n",
    "    # df_indel = read_strelka(strelka_indel_path)\n",
    "    # tusv_ext_indel = convert_strelka_to_tusv_ext_df(df_indel, \"INDEL\")\n",
    "    # write_df_to_vcf(tusv_ext_indel, output_file_path)\n",
    "\n",
    "\n",
    "    df_manta_sv = read_manta_sv(manta_sv_path)\n",
    "    df_processed_manta = rewrite_manta_results(df_manta_sv)\n",
    "    write_df_to_vcf(df_processed_manta, output_file_path)\n",
    "    \n",
    "\n",
    "    cnvkit_df = load_cnvkit_cns(cnvkit_cns_path)\n",
    "    vcf_df = cnvkit_to_df(cnvkit_df)\n",
    "    write_df_to_vcf(vcf_df, output_file_path)\n",
    "\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24d92fda-3a55-4145-94b0-0353a05933ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/ipykernel_launcher.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# ChatGPT modified version 2.0\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "from io import StringIO\n",
    "import re\n",
    "\n",
    "# Define global variables\n",
    "cnv_count = 0\n",
    "sv_count = 0\n",
    "snv_count = 0\n",
    "\n",
    "def increment_cnv():\n",
    "    global cnv_count\n",
    "    cnv_count += 1\n",
    "\n",
    "def increment_sv():\n",
    "    global sv_count\n",
    "    sv_count += 1\n",
    "\n",
    "def increment_snv():\n",
    "    global snv_count\n",
    "    snv_count += 1\n",
    "\n",
    "def convert_chromosome(chrom):\n",
    "    if chrom == 'chrX':\n",
    "        return 23\n",
    "    elif chrom == \"chrY\":\n",
    "        return 24\n",
    "    else:\n",
    "        return int(chrom[3:])\n",
    "\n",
    "def init_vcf(output_folder, sample):\n",
    "    output_file_path = os.path.join(output_folder, sample + '.vcf')\n",
    "    with open(output_file_path, 'w') as file_vcf:\n",
    "        file_vcf.write('##fileformat=VCFv4.2\\n')\n",
    "        file_vcf.write('##filedate=20211011\\n')\n",
    "        file_vcf.write('##INFO=<ID=END,Number=1,Type=Integer,Description=\"End position of the variant described in this record\">\\n')\n",
    "        file_vcf.write('##INFO=<ID=IMPRECISE,Number=0,Type=Flag,Description=\"Imprecise structural variation\">\\n')\n",
    "        file_vcf.write('##INFO=<ID=MATEID,Number=.,Type=String,Description=\"ID of mate breakends\">\\n')\n",
    "        file_vcf.write('##INFO=<ID=SVTYPE,Number=1,Type=String,Description=\"Type of structural variant\">\\n')\n",
    "        file_vcf.write('##FORMAT=<ID=GT,Number=1,Type=Integer,Description=\"Genotype\">\\n')\n",
    "        file_vcf.write('##FORMAT=<ID=CN,Number=2,Type=Integer,Description=\"Copy number genotype for imprecise events\">\\n')\n",
    "        file_vcf.write('##FORMAT=<ID=CNADJ,Number=.,Type=Integer,Description=\"Copy number of adjacency\">\\n')\n",
    "        file_vcf.write('##FORMAT=<ID=BDP,Number=1,Type=Integer,Description=\"Depth of split reads\">\\n')\n",
    "        file_vcf.write('##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read depth\">\\n')\n",
    "        file_vcf.write('##ALT=<ID=DEL,Description=\"Deletion\">\\n')\n",
    "        file_vcf.write('##ALT=<ID=DUP,Description=\"Duplication\">\\n')\n",
    "        file_vcf.write('##ALT=<ID=INS,Description=\"Insertion of novel sequence\">\\n')\n",
    "        file_vcf.write('##ALT=<ID=CNV,Description=\"Copy number variable region\">\\n')\n",
    "        file_vcf.write('#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\\tTUMOR\\tNORMAL\\n')\n",
    "    return output_file_path\n",
    "\n",
    "def write_df_to_vcf(df, vcf_file):\n",
    "    df.to_csv(vcf_file, sep='\\t', mode='a', index=False, header=False)\n",
    "\n",
    "def load_cnvkit_cns(file_path):\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    required_columns = ['chromosome', 'start', 'end', 'log2', 'depth']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Required column '{col}' not found in the .cns file.\")\n",
    "    return df\n",
    "\n",
    "def cnvkit_to_df(cnvkit_df):\n",
    "    vcf_records = []\n",
    "    for idx, row in cnvkit_df.iterrows():\n",
    "        chrom = row['chromosome']\n",
    "        pos = row['start']\n",
    "        id = f'cnv{cnv_count:04d}'\n",
    "        increment_cnv()\n",
    "        ref = '.'\n",
    "        alt = '<CNV>'\n",
    "        qual = '.'\n",
    "        filter = 'PASS'\n",
    "        end = row['end']\n",
    "        info = f'END={end};IMPRECISE'\n",
    "        format_field = 'GT:CN'\n",
    "        tumor_cn = f'1|1:{row[\"log2\"]},{row[\"depth\"]}'\n",
    "        normal_cn = '0|0:1,1'\n",
    "        record = {\n",
    "            '#CHROM': chrom,\n",
    "            'POS': pos,\n",
    "            'ID': id,\n",
    "            'REF': ref,\n",
    "            'ALT': alt,\n",
    "            'QUAL': qual,\n",
    "            'FILTER': filter,\n",
    "            'INFO': info,\n",
    "            'FORMAT': format_field,\n",
    "            'TUMOR': tumor_cn,\n",
    "            'NORMAL': normal_cn\n",
    "        }\n",
    "        vcf_records.append(record)\n",
    "    vcf_df = pd.DataFrame(vcf_records)\n",
    "    return vcf_df\n",
    "\n",
    "def read_strelka(input_file_path):\n",
    "    filtered_lines = []\n",
    "    with gzip.open(input_file_path, 'rt') as file:\n",
    "        for line in file:\n",
    "            if not line.startswith('##'):\n",
    "                filtered_lines.append(line)\n",
    "    filtered_content = ''.join(filtered_lines)\n",
    "    df_snv = pd.read_csv(StringIO(filtered_content), sep='\\t')\n",
    "    df_snv['chr'] = df_snv['#CHROM'].apply(convert_chromosome)\n",
    "    return df_snv\n",
    "\n",
    "def convert_strelka_to_tusv_ext_df(strelka_df, option):\n",
    "    tusv_ext_rows = []\n",
    "    strelka_df = strelka_df[strelka_df[\"FILTER\"] == \"PASS\"]\n",
    "    strelka_df.reset_index(inplace=True)\n",
    "    for index, row in strelka_df.iterrows():\n",
    "        chrom = row['#CHROM']\n",
    "        pos = row['POS']\n",
    "        ref = row['REF']\n",
    "        alt = row['ALT']\n",
    "        if option == \"SNV\":\n",
    "            variant_id = f\"snv{snv_count:04d}\"\n",
    "            increment_snv()\n",
    "            format_field = 'GT:CNADJ'\n",
    "            tumor_data = f'0|1:{row[\"TUMOR\"]}'\n",
    "            normal_data = f'0|0:{row[\"NORMAL\"]}'\n",
    "        elif option == \"INDEL\":\n",
    "            variant_id = f\"sv{sv_count:04d}\"\n",
    "            increment_sv()\n",
    "            format_field = 'GT:CNADJ:BDP:DP'\n",
    "            tumor_data = f'1|0:{row[\"TUMOR\"]}:0:0'\n",
    "            normal_data = f'0|0:{row[\"NORMAL\"]}:0:0'\n",
    "        qual = \".\"\n",
    "        filter_val = row[\"FILTER\"]\n",
    "        info = \".\"\n",
    "        tusv_ext_rows.append([\n",
    "            chrom, pos, variant_id, ref, alt, qual, filter_val, info, format_field, tumor_data, normal_data\n",
    "        ])\n",
    "    tusv_ext_df = pd.DataFrame(tusv_ext_rows, columns=[\n",
    "        '#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'TUMOR', 'NORMAL'\n",
    "    ])\n",
    "    return tusv_ext_df\n",
    "\n",
    "def read_manta_sv(input_file_path):\n",
    "    filtered_lines = []\n",
    "    with gzip.open(input_file_path, 'rt') as file:\n",
    "        for line in file:\n",
    "            if not line.startswith('##'):\n",
    "                filtered_lines.append(line)\n",
    "    filtered_content = ''.join(filtered_lines)\n",
    "    df_manta_sv = pd.read_csv(StringIO(filtered_content), sep='\\t')\n",
    "    return df_manta_sv\n",
    "\n",
    "\n",
    "# This function needs a rewrite. ChatGPT can't handle it\n",
    "\n",
    "def rewrite_manta_results(df):\n",
    "    # Filter for BND types and paired breakpoints\n",
    "    bnd_df = df[df['INFO'].str.contains(\"SVTYPE=BND\")]\n",
    "\n",
    "    # Split the INFO column into a dictionary for easy access\n",
    "    bnd_df['INFO_DICT'] = bnd_df['INFO'].apply(lambda x: dict(item.split('=') for item in x.split(';') if '=' in item))\n",
    "\n",
    "    # Filter out unpaired BNDs\n",
    "    mate_ids = bnd_df['INFO_DICT'].apply(lambda x: x.get('MATEID', None))\n",
    "    paired_bnd_df = bnd_df[bnd_df['ID'].isin(mate_ids.values)]\n",
    "\n",
    "    # Prepare new VCF columns\n",
    "    vcf_columns = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'TUMOR', 'NORMAL']\n",
    "    vcf_df = pd.DataFrame(columns=vcf_columns)\n",
    "\n",
    "    # Create a dictionary to store the paired rows\n",
    "    paired_rows = {}\n",
    "    for index, row in paired_bnd_df.iterrows():\n",
    "        mate_id = row['INFO_DICT']['MATEID']\n",
    "        paired_rows[row['ID']] = row\n",
    "        if mate_id in paired_rows:\n",
    "            mate_row = paired_rows[mate_id]\n",
    "\n",
    "            # Create the ALT field\n",
    "            alt = f\"[{row['#CHROM']}:{mate_row['POS']}[\" if row['ALT'].startswith('[') else f\"]{row['#CHROM']}:{mate_row['POS']}]\"\n",
    "\n",
    "            # Create the INFO field\n",
    "            info = f\"MATEID={mate_id};SVTYPE=BND\"\n",
    "\n",
    "            # Create the FORMAT fields\n",
    "            format_field = \"GT:CNADJ:BDP:DP\"\n",
    "            tumor_data = \"1|0:0.54:1:1\"\n",
    "            normal_data = \"0|0:0:0:1\"\n",
    "\n",
    "            # Append the rows to the new DataFrame\n",
    "            vcf_df = vcf_df.append({\n",
    "                '#CHROM': row['#CHROM'], 'POS': row['POS'], 'ID': row['ID'], 'REF': row['REF'],\n",
    "                'ALT': alt, 'QUAL': row['QUAL'], 'FILTER': row['FILTER'], 'INFO': info,\n",
    "                'FORMAT': format_field, 'TUMOR': tumor_data, 'NORMAL': normal_data\n",
    "            }, ignore_index=True)\n",
    "            \n",
    "            # Append the mate row\n",
    "            alt_mate = f\"[{mate_row['#CHROM']}:{row['POS']}[\" if mate_row['ALT'].startswith('[') else f\"]{mate_row['#CHROM']}:{row['POS']}]\"\n",
    "            info_mate = f\"MATEID={row['ID']};SVTYPE=BND\"\n",
    "            vcf_df = vcf_df.append({\n",
    "                '#CHROM': mate_row['#CHROM'], 'POS': mate_row['POS'], 'ID': mate_row['ID'], 'REF': mate_row['REF'],\n",
    "                'ALT': alt_mate, 'QUAL': mate_row['QUAL'], 'FILTER': mate_row['FILTER'], 'INFO': info_mate,\n",
    "                'FORMAT': format_field, 'TUMOR': tumor_data, 'NORMAL': normal_data\n",
    "            }, ignore_index=True)\n",
    "\n",
    "    return vcf_df\n",
    "    \n",
    "def main():\n",
    "    global cnv_count, sv_count, snv_count\n",
    "    cnv_count = 0\n",
    "    sv_count = 0\n",
    "    snv_count = 0\n",
    "    variant_calling_folder = '/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/TUSV-ext/variant_calling'\n",
    "    output_folder = '/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/TUSV-ext/compiled_input/'\n",
    "    sample_name = 'AUR-AER5-TTM4_vs_AUR-AER5-NT2'\n",
    "    strelka_snv_path = os.path.join(variant_calling_folder, 'strelka', sample_name, sample_name + '.strelka.somatic_snvs.vcf.gz')\n",
    "    strelka_indel_path = os.path.join(variant_calling_folder, 'strelka', sample_name, sample_name + '.strelka.somatic_indels.vcf.gz')\n",
    "    manta_sv_path = os.path.join(variant_calling_folder, 'manta', sample_name, sample_name + '.manta.somatic_sv.vcf.gz')\n",
    "    cnvkit_cns_path = os.path.join(variant_calling_folder, 'cnvkit', sample_name, sample_name.split('_vs_')[0] + '.cns')\n",
    "\n",
    "    output_file_path = init_vcf(output_folder, sample_name)\n",
    "    df_snv = read_strelka(strelka_snv_path)\n",
    "    tusv_ext_snv = convert_strelka_to_tusv_ext_df(df_snv, \"SNV\")\n",
    "    write_df_to_vcf(tusv_ext_snv, output_file_path)\n",
    "\n",
    "    df_manta_sv = read_manta_sv(manta_sv_path)\n",
    "    df_processed_manta = rewrite_manta_results(df_manta_sv)\n",
    "    write_df_to_vcf(df_processed_manta, output_file_path)\n",
    "\n",
    "    cnvkit_df = load_cnvkit_cns(cnvkit_cns_path)\n",
    "    vcf_df = cnvkit_to_df(cnvkit_df)\n",
    "    write_df_to_vcf(vcf_df, output_file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87d385f6-f859-421f-86d7-7827e31bf226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/vcfpy/parser.py:253: CannotConvertValue: 0|1 cannot be converted to Integer, keeping as string.\n",
      "  CannotConvertValue,\n",
      "/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/vcfpy/parser.py:253: CannotConvertValue: 0|0 cannot be converted to Integer, keeping as string.\n",
      "  CannotConvertValue,\n",
      "/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/vcfpy/header.py:415: FieldInfoNotFound: INFO SVLEN not found using Integer/1 instead\n",
      "  FieldInfoNotFound,\n",
      "/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/vcfpy/parser.py:253: CannotConvertValue:  cannot be converted to Integer, keeping as string.\n",
      "  CannotConvertValue,\n",
      "/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/vcfpy/parser.py:253: CannotConvertValue: 214,3 cannot be converted to Integer, keeping as string.\n",
      "  CannotConvertValue,\n",
      "/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/vcfpy/parser.py:253: CannotConvertValue: 445.6 cannot be converted to Integer, keeping as string.\n",
      "  CannotConvertValue,\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '214,3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e3135f84a65c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvcf_reader\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mvcfpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/TUSV-ext/compiled_input/AUR-AER5-TTM4_vs_AUR-AER5-NT2.vcf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvcf_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/vcfpy/reader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtabix_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_next_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/vcfpy/parser.py\u001b[0m in \u001b[0;36mparse_next_record\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0mproblems\u001b[0m \u001b[0mreading\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_next_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_warn_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/vcfpy/parser.py\u001b[0m in \u001b[0;36mparse_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Pare the given line without reading another one from the stream\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_next_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/vcfpy/parser.py\u001b[0m in \u001b[0;36mparse_line\u001b[0;34m(self, line_str)\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0mformat_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;31m# sample/call columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mcalls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_calls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchrom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/vcfpy/parser.py\u001b[0m in \u001b[0;36m_handle_calls\u001b[0;34m(self, alts, format_, format_str, arr)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_calls_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mformat_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m                 \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_checker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_filters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FORMAT/FT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/vcfpy/record.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sample, data, site)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m#: the number of alleles in this sample's call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mploidy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_genotype_updated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_genotype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenotype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/vcfpy/record.py\u001b[0m in \u001b[0;36m_genotype_updated\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_alleles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_alleles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallele\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_alleles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mploidy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_alleles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '214,3'"
     ]
    }
   ],
   "source": [
    "import vcfpy\n",
    "\n",
    "vcf_reader =  vcfpy.Reader.from_path('/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/TUSV-ext/compiled_input/AUR-AER5-TTM4_vs_AUR-AER5-NT2.vcf')\n",
    "\n",
    "for record in vcf_reader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66902b23-a47b-440a-a0e5-bd488c04d464",
   "metadata": {},
   "source": [
    "import vcf\n",
    "\n",
    "vcf_reader = vcf.Reader(open('/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/TUSV-ext/compiled_input/AUR-AER5-TTM4_vs_AUR-AER5-NT2.vcf', 'r'))\n",
    "\n",
    "for record in vcf_reader:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb034b-ff4a-4177-8941-d7d0badddb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to add an option so SNVs are given SNV IDs but strelka indels are given SV ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "174cd4e2-fb66-485b-b9b3-fcafa3ced517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #CHROM    POS ID REF ALT QUAL  FILTER  \\\n",
      "0   chr1  10120  .   T   C    .  LowEVS   \n",
      "1   chr1  10257  .   A   C    .  LowEVS   \n",
      "2   chr1  10330  .   C   A    .  LowEVS   \n",
      "3   chr1  14063  .   G   A    .  LowEVS   \n",
      "4   chr1  14653  .   C   T    .  LowEVS   \n",
      "\n",
      "                                                INFO  \\\n",
      "0  DP=1080;MQ=12.08;MQ0=874;NT=ref;QSS=8;QSS_NT=8...   \n",
      "1  DP=190;MQ=16.38;MQ0=92;NT=ref;QSS=3;QSS_NT=3;R...   \n",
      "2  DP=212;MQ=21.15;MQ0=89;NT=ref;QSS=1;QSS_NT=1;R...   \n",
      "3  DP=37;MQ=18.01;MQ0=25;NT=ref;QSS=1;QSS_NT=1;Re...   \n",
      "4  DP=45;MQ=29.11;MQ0=14;NT=ref;QSS=4;QSS_NT=4;Re...   \n",
      "\n",
      "                         FORMAT                         NORMAL  \\\n",
      "0  DP:FDP:SDP:SUBDP:AU:CU:GU:TU  48:18:1:0:2,19:0,2:0,2:28,112   \n",
      "1  DP:FDP:SDP:SUBDP:AU:CU:GU:TU      12:7:1:0:5,41:0,5:0,0:0,0   \n",
      "2  DP:FDP:SDP:SUBDP:AU:CU:GU:TU     26:19:6:0:0,5:7,23:0,1:0,1   \n",
      "3  DP:FDP:SDP:SUBDP:AU:CU:GU:TU       3:0:0:0:0,0:0,0:3,14:0,0   \n",
      "4  DP:FDP:SDP:SUBDP:AU:CU:GU:TU     14:0:0:0:0,0:12,18:0,0:2,3   \n",
      "\n",
      "                          TUMOR  chr                          data  \n",
      "0  48:17:0:0:2,14:3,4:0,5:26,91    1  48:17:0:0:2,14:3,4:0,5:26,91  \n",
      "1   19:14:2:0:3,50:2,10:0,0:0,0    1   19:14:2:0:3,50:2,10:0,0:0,0  \n",
      "2   29:22:1:0:2,11:5,24:0,0:0,0    1   29:22:1:0:2,11:5,24:0,0:0,0  \n",
      "3      4:0:0:0:2,2:0,0:2,21:0,0    1      4:0:0:0:2,2:0,0:2,21:0,0  \n",
      "4    15:0:0:0:0,0:13,22:0,0:2,2    1    15:0:0:0:0,0:13,22:0,0:2,2  \n",
      "(1305762, 13)\n",
      "(27859, 13)\n",
      "  #CHROM     POS      ID REF ALT QUAL FILTER INFO    FORMAT  TUMOR NORMAL\n",
      "0   chr1  202192  sv0000   T   C    .   PASS    .  GT:CNADJ  0|1:0  0|0:0\n",
      "1   chr1  791204  sv0001   T   C    .   PASS    .  GT:CNADJ  0|1:0  0|0:0\n",
      "2   chr1  795801  sv0002   G   A    .   PASS    .  GT:CNADJ  0|1:0  0|0:0\n",
      "3   chr1  818228  sv0003   T   A    .   PASS    .  GT:CNADJ  0|1:0  0|0:0\n",
      "4   chr1  881300  sv0004   G   T    .   PASS    .  GT:CNADJ  0|1:0  0|0:0\n"
     ]
    }
   ],
   "source": [
    "# Test box for reading in Strelka indel files to test\n",
    "\n",
    "test_strelka_indel_path = '/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/wholebody_phylo/AER5_results/variant_calling/strelka/AUR-AER5-TTM4_vs_AUR-AER5-NT2/AUR-AER5-TTM4_vs_AUR-AER5-NT2.strelka.somatic_snvs.vcf.gz'\n",
    "\n",
    "df_indel = read_strelka(test_strelka_indel_path)\n",
    "\n",
    "\n",
    "print(df_indel.head())\n",
    "tusv_ext_indel = convert_strelka_to_tusv_ext_df(df_indel, \"INDEL\")\n",
    "print(tusv_ext_indel.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e3464e2-58c7-47ed-bd5c-2f7d79896fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14497, 13)\n",
      "(5411, 13)\n",
      "  #CHROM      POS       ID REF               ALT QUAL FILTER INFO    FORMAT  \\\n",
      "0   chr1  1056668  snv0000   C               CGT    .   PASS    .  GT:CNADJ   \n",
      "1   chr1  1423775  snv0001   C                CT    .   PASS    .  GT:CNADJ   \n",
      "2   chr1  1509914  snv0002  TA                 T    .   PASS    .  GT:CNADJ   \n",
      "3   chr1  2900016  snv0003   C                CG    .   PASS    .  GT:CNADJ   \n",
      "4   chr1  3329041  snv0004   G  GCCTTCTCCCTGGGCC    .   PASS    .  GT:CNADJ   \n",
      "\n",
      "   TUMOR NORMAL  \n",
      "0  0|1:0  0|0:0  \n",
      "1  0|1:0  0|0:0  \n",
      "2  0|1:0  0|0:0  \n",
      "3  0|1:0  0|0:0  \n",
      "4  0|1:0  0|0:0  \n"
     ]
    }
   ],
   "source": [
    "# Test box for reading in Strelka snv files to test.\n",
    "import sys\n",
    "\n",
    "test_strelka_snv_path = '/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/wholebody_phylo/AER5_results/variant_calling/strelka/AUR-AER5-TTM4_vs_AUR-AER5-NT2/AUR-AER5-TTM4_vs_AUR-AER5-NT2.strelka.somatic_indels.vcf.gz'\n",
    "\n",
    "df_snv = read_strelka(test_strelka_snv_path)\n",
    "\n",
    "tusv_ext_snv = convert_strelka_to_tusv_ext_df(df_snv, \"SNV\")\n",
    "print(tusv_ext_snv.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9a2a282-781c-4c9e-9d2b-c22101d9440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  chromosome    start       end gene      log2     depth  probes     weight  \\\n",
      "0       chr1    14034    351968    -  0.098452  14.55930      58    52.1960   \n",
      "1       chr1   351968    459979    - -0.413539   7.87716      27    19.1118   \n",
      "2       chr1   459979   1264807    - -0.022918  13.51170     180   170.4730   \n",
      "3       chr1  1264807   1333091    -  0.322362  17.72340      17    16.8359   \n",
      "4       chr1  1333091  16558479    - -0.011359  13.51330    3752  3682.8400   \n",
      "\n",
      "      ci_lo     ci_hi  \n",
      "0  0.080594  0.119033  \n",
      "1 -0.444376 -0.386697  \n",
      "2 -0.031888 -0.010873  \n",
      "3  0.294485  0.344509  \n",
      "4 -0.013140 -0.009817  \n",
      "  #CHROM      POS     ID REF    ALT QUAL FILTER                    INFO  \\\n",
      "0   chr1    14034  cnv00   .  <CNV>    .   PASS    END=351968;IMPRECISE   \n",
      "1   chr1   351968  cnv01   .  <CNV>    .   PASS    END=459979;IMPRECISE   \n",
      "2   chr1   459979  cnv02   .  <CNV>    .   PASS   END=1264807;IMPRECISE   \n",
      "3   chr1  1264807  cnv03   .  <CNV>    .   PASS   END=1333091;IMPRECISE   \n",
      "4   chr1  1333091  cnv04   .  <CNV>    .   PASS  END=16558479;IMPRECISE   \n",
      "\n",
      "  FORMAT                   TUMOR   NORMAL  \n",
      "0  GT:CN   1|1:0.0984518,14.5593  0|0:1,1  \n",
      "1  GT:CN   1|1:-0.413539,7.87716  0|0:1,1  \n",
      "2  GT:CN  1|1:-0.0229176,13.5117  0|0:1,1  \n",
      "3  GT:CN    1|1:0.322362,17.7234  0|0:1,1  \n",
      "4  GT:CN  1|1:-0.0113593,13.5133  0|0:1,1  \n"
     ]
    }
   ],
   "source": [
    "# Test box for reading in CNVKit .cns files to test.\n",
    "\n",
    "test_cnvkit_cns_file = '/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/wholebody_phylo/AER5_results/variant_calling/cnvkit/AUR-AER5-TTM4_vs_AUR-AER5-NT2/AUR-AER5-TTM4.cns'\n",
    "\n",
    "cnvkit_df = load_cnvkit_cns(test_cnvkit_cns_file)\n",
    "print(cnvkit_df.head())\n",
    "\n",
    "vcf_df = cnvkit_to_df(cnvkit_df)\n",
    "print(vcf_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e89c704e-7841-4e28-bfba-2e5466d8d68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #CHROM       POS                               ID REF                 ALT  \\\n",
      "0   chr1   3722167       MantaBND:11184:1:3:0:0:0:1   A     A]chr1:3722443]   \n",
      "1   chr1   3722434       MantaBND:11184:1:3:0:0:0:0   A     A]chr1:3722176]   \n",
      "2   chr1  10413332       MantaBND:73506:1:1:6:0:0:1   T    T]chr1:10413436]   \n",
      "3   chr1  10413428       MantaBND:73506:1:1:6:0:0:0   T    T]chr1:10413340]   \n",
      "4   chr1  15349115       MantaBND:87210:0:0:1:0:0:1   A    A]chr1:15349202]   \n",
      "5   chr1  15349194       MantaBND:87210:0:0:1:0:0:0   G    G]chr1:15349123]   \n",
      "6   chr1  16996026   MantaBND:1:97014:97014:1:0:0:0   G    [chr1:16996118[G   \n",
      "7   chr1  16996113   MantaBND:1:97014:97014:1:0:0:1   C    [chr1:16996031[C   \n",
      "8   chr1  20792077   MantaBND:1:31559:31577:0:0:0:1   G  GT]chr18:37273578]   \n",
      "9   chr1  20867797  MantaDUP:TANDEM:12529:1:7:0:1:0   A        <DUP:TANDEM>   \n",
      "\n",
      "  QUAL           FILTER                                               INFO  \\\n",
      "0    .  MinSomaticScore  SVTYPE=BND;MATEID=MantaBND:11184:1:3:0:0:0:0;C...   \n",
      "1    .  MinSomaticScore  SVTYPE=BND;MATEID=MantaBND:11184:1:3:0:0:0:1;C...   \n",
      "2    .  MinSomaticScore  SVTYPE=BND;MATEID=MantaBND:73506:1:1:6:0:0:0;C...   \n",
      "3    .  MinSomaticScore  SVTYPE=BND;MATEID=MantaBND:73506:1:1:6:0:0:1;C...   \n",
      "4    .  MinSomaticScore  SVTYPE=BND;MATEID=MantaBND:87210:0:0:1:0:0:0;C...   \n",
      "5    .  MinSomaticScore  SVTYPE=BND;MATEID=MantaBND:87210:0:0:1:0:0:1;C...   \n",
      "6    .  MinSomaticScore  SVTYPE=BND;MATEID=MantaBND:1:97014:97014:1:0:0...   \n",
      "7    .  MinSomaticScore  SVTYPE=BND;MATEID=MantaBND:1:97014:97014:1:0:0...   \n",
      "8    .  MinSomaticScore  SVTYPE=BND;MATEID=MantaBND:1:31559:31577:0:0:0...   \n",
      "9    .  MinSomaticScore  END=117102440;SVTYPE=DUP;SVLEN=96234643;CIPOS=...   \n",
      "\n",
      "  FORMAT AUR-AER5_AUR-AER5-NT2 AUR-AER5_AUR-AER5-TTM4  \n",
      "0  PR:SR            99,0:207,0            121,2:288,3  \n",
      "1  PR:SR            99,0:207,0            121,2:288,3  \n",
      "2  PR:SR             16,0:57,0              20,2:68,2  \n",
      "3  PR:SR             16,0:57,0              20,2:68,2  \n",
      "4  PR:SR            60,0:146,0            100,2:240,2  \n",
      "5  PR:SR            60,0:146,0            100,2:240,2  \n",
      "6  PR:SR           166,0:437,0            199,2:504,3  \n",
      "7  PR:SR           166,0:437,0            199,2:504,3  \n",
      "8  PR:SR           103,0:252,0            183,2:418,3  \n",
      "9  PR:SR              1,0:16,0               0,0:15,3  \n"
     ]
    }
   ],
   "source": [
    "# Test box for reading in Manta .vcf files to determine format.\n",
    "\n",
    "test_manta_file = '/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/wholebody_phylo/AER5_results/variant_calling/manta/AUR-AER5-TTM4_vs_AUR-AER5-NT2/AUR-AER5-TTM4_vs_AUR-AER5-NT2.manta.somatic_sv.vcf.gz'\n",
    "test_organoid_wes_file = '/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/nfcore/achang4_bridgesPSC/sarek/Part2_FASTQ2SAREK/results/variant_calling/manta/123_organoid_vs_123_blood/123_organoid_vs_123_blood.manta.somatic_sv.vcf.gz'\n",
    "test_manta_wes_file = '/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/TUSV-ext/variant_calling/manta/AUR-AER5-TTM4_vs_AUR-AER5-NT2/AUR-AER5-TTM4_vs_AUR-AER5-NT2.manta.somatic_sv.vcf.gz'\n",
    "\n",
    "df_processed_manta = read_manta_sv(test_manta_wes_file)\n",
    "\n",
    "print(df_processed_manta.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c1427d-4c89-4117-8ca4-b25b6d4a540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceed with WES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f9386-5616-4fcd-b384-f3a39a03a1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TUSV-ext",
   "language": "python",
   "name": "tusv_ext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
