{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d92fda-3a55-4145-94b0-0353a05933ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Created pseudo-normal VCF at: /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/TUSV-ext/AFEC_compiled_input_wSVs/pseudo_normal.vcf\n",
      "INFO:root:Collecting variants for AUR-AFEC-TTM1_vs_AUR-AFEC-NT1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 248956422, '2': 242193529, '3': 198295559, '4': 190214555, '5': 181538259, '6': 170805979, '7': 159345973, '8': 145138636, '9': 138394717, '10': 133797422, '11': 135086622, '12': 133275309, '13': 114364328, '14': 107043718, '15': 101991189, '16': 90338345, '17': 83257441, '18': 80373285, '19': 58617616, '20': 64444167, '21': 46709983, '22': 50818468, '23': 156040895, '24': 57227415}\n",
      "  chr   startpos     endpos  nMajor  nMinor\n",
      "0   1     873251  125122318       3       0\n",
      "1   1  145772225  248916508       3       2\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "2   2     41404  241893909       2       1\n",
      "  chr   startpos     endpos  nMajor  nMinor\n",
      "3   3      29609  176693190       2       0\n",
      "4   3  176988530  198058940       3       0\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "5   4     85531  189446500       2       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "6   5    140417   57653379       2       2\n",
      "7   5  57653695  181155980       2       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "8   6    397290  170583760       3       0\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "9   7     81400  159295340       2       2\n",
      "   chr   startpos     endpos  nMajor  nMinor\n",
      "10   8     244884   42341776       1       1\n",
      "11   8   42484636  101130015       2       1\n",
      "12   8  101199955  144995060       3       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "13   9    154933   13147765       2       1\n",
      "14   9  13147904   17298728       1       0\n",
      "15   9  17299576   17394227       2       0\n",
      "16   9  17447448  138181722       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "17  10     48486   61940469       2       1\n",
      "18  10  62050693  133557962       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "19  11    199813   78856322       2       1\n",
      "20  11  78890268  135030575       1       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "21  12    140964   33582000       3       2\n",
      "22  12  34165416  133219447       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "23  13  18743175  114324544       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "24  14  19921447  106650465       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "25  15  19897077  101829176       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "26  16     34170  90096325       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "27  17    161952  21210841       2       0\n",
      "28  17  21298238  83048974       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "29  18     86837  14890132       2       2\n",
      "30  18  20970650  80159596       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "31  19    282753  24163431       3       0\n",
      "32  19  27755327  58478128       3       2\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "33  20    145888  64273189       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "34  21  13249222  46602462       3       0\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "35  22  16104906  50580150       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "36  23    346920  155774775       1       1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/ipykernel_launcher.py:418: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PR:SR' 'PR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Collected variants for AUR-AFEC-TTM1_vs_AUR-AFEC-NT1: CNVs: 97, SVs: 494, SNVs: 2546\n",
      "INFO:root:Collecting variants for AUR-AFEC-TTM3_vs_AUR-AFEC-NT1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 248956422, '2': 242193529, '3': 198295559, '4': 190214555, '5': 181538259, '6': 170805979, '7': 159345973, '8': 145138636, '9': 138394717, '10': 133797422, '11': 135086622, '12': 133275309, '13': 114364328, '14': 107043718, '15': 101991189, '16': 90338345, '17': 83257441, '18': 80373285, '19': 58617616, '20': 64444167, '21': 46709983, '22': 50818468, '23': 156040895, '24': 57227415}\n",
      "  chr   startpos     endpos  nMajor  nMinor\n",
      "0   1     873251  125122318       3       0\n",
      "1   1  145772225  248916508       3       2\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "2   2     41404   94887291       2       1\n",
      "3   2  94892770  241893909       3       1\n",
      "  chr   startpos     endpos  nMajor  nMinor\n",
      "4   3      29609   60525404       3       0\n",
      "5   3   60537235  177265734       2       0\n",
      "6   3  177589854  198058940       4       0\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "7   4     85531  189446500       2       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "8   5    140417   58458178       2       2\n",
      "9   5  58458981  181155980       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "10   6    397290  170583760       3       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "11   7     81400  159295340       2       2\n",
      "   chr   startpos     endpos  nMajor  nMinor\n",
      "12   8     244884   42548897       1       1\n",
      "13   8   42549034  100608313       2       1\n",
      "14   8  100613251  144995060       3       1\n",
      "   chr   startpos     endpos  nMajor  nMinor\n",
      "15   9     154933   13176313       2       1\n",
      "16   9   13196442   17466279       1       0\n",
      "17   9   17486804   21816759       2       1\n",
      "18   9   21838146   26116018       1       0\n",
      "19   9   26116152  101686816       2       1\n",
      "20   9  101687311  138181722       3       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "21  10     48486   61940469       2       1\n",
      "22  10  62050693  133557962       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "23  11    199813  135030575       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "24  12    140964  133219447       2       2\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "25  13  18743175  114324544       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "26  14  19921447  106650465       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "27  15  19897077  101829176       2       2\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "28  16     34170  90096325       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "29  17    161952  21210841       2       0\n",
      "30  17  21298238  83048974       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "31  18     86837  80159596       2       2\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "32  19    282753  24163431       3       0\n",
      "33  19  27755327  58478128       3       2\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "34  20    145888  64273189       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "35  21  13249222  46602462       3       0\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "36  22  16104906  50580150       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "37  23    346920  155774775       1       1\n",
      "['PR:SR' 'PR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/ipykernel_launcher.py:418: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "INFO:root:Collected variants for AUR-AFEC-TTM3_vs_AUR-AFEC-NT1: CNVs: 99, SVs: 224, SNVs: 2611\n",
      "INFO:root:Collecting variants for AUR-AFEC-TTM4_vs_AUR-AFEC-NT1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 248956422, '2': 242193529, '3': 198295559, '4': 190214555, '5': 181538259, '6': 170805979, '7': 159345973, '8': 145138636, '9': 138394717, '10': 133797422, '11': 135086622, '12': 133275309, '13': 114364328, '14': 107043718, '15': 101991189, '16': 90338345, '17': 83257441, '18': 80373285, '19': 58617616, '20': 64444167, '21': 46709983, '22': 50818468, '23': 156040895, '24': 57227415}\n",
      "  chr   startpos     endpos  nMajor  nMinor\n",
      "0   1     873251  125122318       3       0\n",
      "1   1  145772225  248916508       3       2\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "2   2     41404   94876367       2       1\n",
      "3   2  94887038  241893909       3       1\n",
      "  chr   startpos     endpos  nMajor  nMinor\n",
      "4   3      29609  178827986       3       0\n",
      "5   3  178828238  198058940       4       0\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "6   4     85531  189446500       2       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "7   5    140417   57653320       2       2\n",
      "8   5  57653379  181155980       2       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "9   6    397290  170583760       3       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "10   7     81400  159295340       2       2\n",
      "   chr   startpos     endpos  nMajor  nMinor\n",
      "11   8     244884   46595448       1       1\n",
      "12   8   46596061  100596691       2       1\n",
      "13   8  100597031  144995060       3       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "14   9    154933   13987679       2       1\n",
      "15   9  13993596   17466279       1       0\n",
      "16   9  17486804  138181722       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "17  10     48486   62050699       2       1\n",
      "18  10  62093206  133557962       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "19  11    199813  135030575       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "20  12    140964  133219447       2       2\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "21  13  18743175  114324544       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "22  14  19921447  106650465       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "23  15  19897077  101829176       2       2\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "24  16     34170  90096325       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "25  17    161952  21210841       2       0\n",
      "26  17  21298238  83048974       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "27  18     86837  80159596       2       2\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "28  19    282753  24163431       3       0\n",
      "29  19  27755327  58478128       3       2\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "30  20    145888  64273189       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "31  21  13249222  16422688       2       0\n",
      "32  21  16631980  46602462       3       0\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "33  22  16104906  50580150       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "34  23    346920  155774775       1       1\n",
      "['PR:SR' 'PR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/ipykernel_launcher.py:418: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "INFO:root:Collected variants for AUR-AFEC-TTM4_vs_AUR-AFEC-NT1: CNVs: 93, SVs: 124, SNVs: 2336\n",
      "INFO:root:Collecting variants for AUR-AFEC-TTM5_vs_AUR-AFEC-NT1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 248956422, '2': 242193529, '3': 198295559, '4': 190214555, '5': 181538259, '6': 170805979, '7': 159345973, '8': 145138636, '9': 138394717, '10': 133797422, '11': 135086622, '12': 133275309, '13': 114364328, '14': 107043718, '15': 101991189, '16': 90338345, '17': 83257441, '18': 80373285, '19': 58617616, '20': 64444167, '21': 46709983, '22': 50818468, '23': 156040895, '24': 57227415}\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "0   1    873251  248916508       1       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "1   2     41404  241893909       1       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "2   3     29609  198058940       1       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "3   4     85531  189446500       1       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "4   5    140417  181155980       1       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "5   6    397290  170583760       1       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "6   7     81400  159295340       1       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "7   8    244884  144995060       1       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "8   9    154933  138181722       1       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "9  10     48486  133557962       1       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "10  11    199813  135030575       1       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "11  12    140964  133219447       1       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "12  13  18743175  114324544       1       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "13  14  19921447  106650465       1       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "14  15  19897077  101829176       1       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "15  16     34170  90096325       1       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "16  17    161952  83048974       1       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "17  18     86837  80159596       1       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "18  19    282753  58478128       1       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "19  20    145888  64273189       1       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "20  21  13249222  46602462       1       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "21  22  16104906  50580150       1       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "22  23    346920  155774775       1       1\n",
      "['PR:SR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/ipykernel_launcher.py:418: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "INFO:root:Collected variants for AUR-AFEC-TTM5_vs_AUR-AFEC-NT1: CNVs: 69, SVs: 320, SNVs: 1247\n",
      "INFO:root:Collecting variants for AUR-AFEC-TTM6_vs_AUR-AFEC-NT1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 248956422, '2': 242193529, '3': 198295559, '4': 190214555, '5': 181538259, '6': 170805979, '7': 159345973, '8': 145138636, '9': 138394717, '10': 133797422, '11': 135086622, '12': 133275309, '13': 114364328, '14': 107043718, '15': 101991189, '16': 90338345, '17': 83257441, '18': 80373285, '19': 58617616, '20': 64444167, '21': 46709983, '22': 50818468, '23': 156040895, '24': 57227415}\n",
      "  chr   startpos     endpos  nMajor  nMinor\n",
      "0   1     873251  125122318       3       0\n",
      "1   1  145772225  248916508       3       2\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "2   2     41404   94887291       1       1\n",
      "3   2  94892770  241893909       3       1\n",
      "  chr   startpos     endpos  nMajor  nMinor\n",
      "4   3      29609  176988530       2       0\n",
      "5   3  176988814  198058940       3       0\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "6   4     85531  189446500       2       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "7   5    140417   57424168       2       2\n",
      "8   5  57653320  181155980       2       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "9   6    397290  170583760       3       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "10   7     81400  159295340       2       2\n",
      "   chr   startpos     endpos  nMajor  nMinor\n",
      "11   8     244884   42341776       1       1\n",
      "12   8   42484636  100608313       2       1\n",
      "13   8  100613251  144995060       3       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "14   9    154933   13986758       2       1\n",
      "15   9  13987525   17394227       1       0\n",
      "16   9  17447448  138181722       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "17  10     48486   62050699       2       1\n",
      "18  10  62093206  133557962       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "19  11    199813  135030575       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "20  12    140964  133219447       2       2\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "21  13  18743175  114324544       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "22  14  19921447  106650465       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "23  15  19897077  101829176       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "24  16     34170  90096325       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "25  17    161952  21298582       2       0\n",
      "26  17  21298669  83048974       2       2\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "27  18     86837  80159596       2       2\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "28  19    282753  24163431       3       0\n",
      "29  19  27755327  58478128       3       2\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "30  20    145888  64273189       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "31  21  13249222  15849667       2       0\n",
      "32  21  16244821  46602462       3       0\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "33  22  16104906  50580150       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "34  23    346920  155774775       1       1\n",
      "['PR:SR' 'PR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/ipykernel_launcher.py:418: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "INFO:root:Collected variants for AUR-AFEC-TTM6_vs_AUR-AFEC-NT1: CNVs: 93, SVs: 132, SNVs: 2270\n",
      "INFO:root:Collecting variants for AUR-AFEC-TTP2_vs_AUR-AFEC-NT1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 248956422, '2': 242193529, '3': 198295559, '4': 190214555, '5': 181538259, '6': 170805979, '7': 159345973, '8': 145138636, '9': 138394717, '10': 133797422, '11': 135086622, '12': 133275309, '13': 114364328, '14': 107043718, '15': 101991189, '16': 90338345, '17': 83257441, '18': 80373285, '19': 58617616, '20': 64444167, '21': 46709983, '22': 50818468, '23': 156040895, '24': 57227415}\n",
      "  chr   startpos     endpos  nMajor  nMinor\n",
      "0   1     873251  125122318       3       0\n",
      "1   1  145772225  248916508       3       2\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "2   2     41404   94887038       2       1\n",
      "3   2  94887285  241893909       3       1\n",
      "  chr   startpos     endpos  nMajor  nMinor\n",
      "4   3      29609  175233966       2       0\n",
      "5   3  175256388  198058940       4       0\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "6   4     85531  189446500       2       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "7   5    140417   58494510       2       2\n",
      "8   5  58583600  181155980       2       1\n",
      "  chr  startpos     endpos  nMajor  nMinor\n",
      "9   6    397290  170583760       3       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "10   7     81400  159295340       2       2\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "11   8    244884   42484636       1       1\n",
      "12   8  42542386   98455628       2       1\n",
      "13   8  98515434  144995060       3       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "14   9    154933   13108795       2       1\n",
      "15   9  13115423   13176313       2       0\n",
      "16   9  13196442   17486804       1       0\n",
      "17   9  17486986  138181722       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "18  10     48486   61940469       2       1\n",
      "19  10  62050693  133557962       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "20  11    199813  135030575       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "21  12    140964  133219447       2       2\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "22  13  18743175  114324544       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "23  14  19921447  106650465       2       1\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "24  15  19897077  101829176       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "25  16     34170  90096325       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "26  17    161952  21210841       2       0\n",
      "27  17  21298238  83048974       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "28  18     86837  14890132       2       2\n",
      "29  18  20970650  80159596       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "30  19    282753  24163431       3       0\n",
      "31  19  27755327  58478128       3       2\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "32  20    145888  64273189       2       1\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "33  21  13249222  46602462       3       0\n",
      "   chr  startpos    endpos  nMajor  nMinor\n",
      "34  22  16104906  50580150       2       0\n",
      "   chr  startpos     endpos  nMajor  nMinor\n",
      "35  23    346920  155774775       1       1\n",
      "['PR:SR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/tusv_ext/lib/python3.6/site-packages/ipykernel_launcher.py:418: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "INFO:root:Collected variants for AUR-AFEC-TTP2_vs_AUR-AFEC-NT1: CNVs: 95, SVs: 156, SNVs: 2141\n",
      "INFO:root:CNV DataFrame shape: (546, 12)\n",
      "INFO:root:CNV DataFrame columns: ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'TUMOR', 'NORMAL', 'sample']\n",
      "INFO:root:CNV sample distribution: {'AUR-AFEC-TTM3_vs_AUR-AFEC-NT1': 99, 'AUR-AFEC-TTM1_vs_AUR-AFEC-NT1': 97, 'AUR-AFEC-TTP2_vs_AUR-AFEC-NT1': 95, 'AUR-AFEC-TTM4_vs_AUR-AFEC-NT1': 93, 'AUR-AFEC-TTM6_vs_AUR-AFEC-NT1': 93, 'AUR-AFEC-TTM5_vs_AUR-AFEC-NT1': 69}\n",
      "INFO:root:SV DataFrame shape: (1450, 12)\n",
      "INFO:root:SV DataFrame columns: ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'TUMOR', 'NORMAL', 'sample']\n",
      "INFO:root:SV sample distribution: {'AUR-AFEC-TTM1_vs_AUR-AFEC-NT1': 494, 'AUR-AFEC-TTM5_vs_AUR-AFEC-NT1': 320, 'AUR-AFEC-TTM3_vs_AUR-AFEC-NT1': 224, 'AUR-AFEC-TTP2_vs_AUR-AFEC-NT1': 156, 'AUR-AFEC-TTM6_vs_AUR-AFEC-NT1': 132, 'AUR-AFEC-TTM4_vs_AUR-AFEC-NT1': 124}\n",
      "INFO:root:SNV DataFrame shape: (13151, 12)\n",
      "INFO:root:SNV DataFrame columns: ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'TUMOR', 'NORMAL', 'sample']\n",
      "INFO:root:SNV sample distribution: {'AUR-AFEC-TTM3_vs_AUR-AFEC-NT1': 2611, 'AUR-AFEC-TTM1_vs_AUR-AFEC-NT1': 2546, 'AUR-AFEC-TTM4_vs_AUR-AFEC-NT1': 2336, 'AUR-AFEC-TTM6_vs_AUR-AFEC-NT1': 2270, 'AUR-AFEC-TTP2_vs_AUR-AFEC-NT1': 2141, 'AUR-AFEC-TTM5_vs_AUR-AFEC-NT1': 1247}\n",
      "ERROR:root:An error occurred: name 'chromosome_lengths' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-3-56a22808e94b>\", line 740, in main\n",
      "    cnv_df, sv_df, snv_df = assign_consistent_ids(cnv_df, sv_df, snv_df, used_ids)\n",
      "  File \"<ipython-input-3-56a22808e94b>\", line 694, in assign_consistent_ids\n",
      "    cnv_id = f\"cnv{row['#CHROM']}\" if row['POS'] == 1 and row['INFO'].endswith(f\"END={chromosome_lengths[row['#CHROM']]}\") else f\"cnv{get_next_id('cnv', cnv_current_id)}\"\n",
      "NameError: name 'chromosome_lengths' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Working version, unfortunately now needs to have static SV identity\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "from io import StringIO\n",
    "import re\n",
    "import sys\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Define global variables\n",
    "cnv_count = 1\n",
    "sv_count = 1\n",
    "snv_count = 1\n",
    "\n",
    "def increment_cnv():\n",
    "    global cnv_count\n",
    "    cnv_count += 1\n",
    "\n",
    "def increment_sv():\n",
    "    global sv_count\n",
    "    sv_count += 1\n",
    "\n",
    "def increment_snv():\n",
    "    global snv_count\n",
    "    snv_count += 1\n",
    "\n",
    "def convert_chromosome(chrom):\n",
    "    if chrom == 'chrX' or chrom == 'X':\n",
    "        return \"23\"\n",
    "    elif chrom == \"chrY\" or chrom == 'Y':\n",
    "        return \"24\"\n",
    "    elif chrom.startswith('chr'):\n",
    "        return str(chrom[3:])\n",
    "    else:\n",
    "        return str(chrom)\n",
    "\n",
    "def init_vcf(output_folder, sample):\n",
    "    output_file_path = os.path.join(output_folder, sample + '.vcf')\n",
    "    with open(output_file_path, 'w') as file_vcf:\n",
    "        file_vcf.write('##fileformat=VCFv4.2\\n')\n",
    "        file_vcf.write('##filedate=20211011\\n')\n",
    "        file_vcf.write('##INFO=<ID=END,Number=1,Type=Integer,Description=\"End position of the variant described in this record\">\\n')\n",
    "        file_vcf.write('##INFO=<ID=IMPRECISE,Number=0,Type=Flag,Description=\"Imprecise structural variation\">\\n')\n",
    "        file_vcf.write('##INFO=<ID=MATEID,Number=.,Type=String,Description=\"ID of mate breakends\">\\n')\n",
    "        file_vcf.write('##INFO=<ID=SVTYPE,Number=1,Type=String,Description=\"Type of structural variant\">\\n')\n",
    "        file_vcf.write('##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\\n')\n",
    "        file_vcf.write('##FORMAT=<ID=CN,Number=2,Type=Integer,Description=\"Copy number genotype for imprecise events\">\\n')\n",
    "        file_vcf.write('##FORMAT=<ID=CNADJ,Number=.,Type=Float,Description=\"Copy number of adjacency\">\\n')\n",
    "        file_vcf.write('##FORMAT=<ID=BDP,Number=1,Type=Integer,Description=\"Depth of split reads\">\\n')\n",
    "        file_vcf.write('##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read depth\">\\n')\n",
    "        file_vcf.write('##ALT=<ID=DEL,Description=\"Deletion\">\\n')\n",
    "        file_vcf.write('##ALT=<ID=DUP,Description=\"Duplication\">\\n')\n",
    "        file_vcf.write('##ALT=<ID=INS,Description=\"Insertion of novel sequence\">\\n')\n",
    "        file_vcf.write('##ALT=<ID=CNV,Description=\"Copy number variable region\">\\n')\n",
    "        file_vcf.write('#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\\tTUMOR\\tNORMAL\\n')\n",
    "    return output_file_path\n",
    "\n",
    "def write_df_to_vcf(df, vcf_file):\n",
    "    # Filter out rows where #CHROM column has the value 24\n",
    "    # Ensure the #CHROM column is treated as a string\n",
    "    df['#CHROM'] = df['#CHROM'].astype(str)\n",
    "    \n",
    "    # Perform the filtering operation\n",
    "    filtered_df = df[df['#CHROM'] != '24']\n",
    "    filtered_df.to_csv(vcf_file, sep='\\t', mode='a', index=False, header=False)\n",
    "\n",
    "\n",
    "def load_ascat_cnv(file_path):\n",
    "    \"\"\"\n",
    "    Reads an ASCAT output file into a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the ASCAT output file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the ASCAT data.\n",
    "    \"\"\"\n",
    "    # Define column names as specified in the example\n",
    "    column_names = ['chr', 'startpos', 'endpos', 'nMajor', 'nMinor']\n",
    "    \n",
    "    # Read the file into a DataFrame\n",
    "    df = pd.read_csv(file_path, sep='\\t', names=column_names, header=0)\n",
    "    df['chr'] = df['chr'].apply(convert_chromosome)\n",
    "    return df\n",
    "\n",
    "def convert_ascat_to_vcf_df(df, reference_genome_path):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame with ASCAT data to a VCF compatible DataFrame,\n",
    "    adding rows for all segments of each chromosome that are not already in the data.\n",
    "    \"\"\"\n",
    "    vcf_records = []\n",
    "    chromosome_lengths = {}\n",
    "    cnv_count = 0\n",
    "\n",
    "\n",
    "\n",
    "    # Parse the reference genome file\n",
    "    for record in SeqIO.parse(reference_genome_path, \"fasta\"):\n",
    "        chromosome = record.id\n",
    "        length = len(record.seq)\n",
    "        if chromosome.startswith(\"NC_0000\"):\n",
    "            chromosome_number = chromosome.split('.')[0].replace(\"NC_0000\", \"\")\n",
    "            chromosome_number = str(int(chromosome_number))  # Remove leading zeros\n",
    "            chromosome_lengths[chromosome_number] = length\n",
    "        elif chromosome.startswith(\"NC_012920.1\"):\n",
    "            # Skip the MT chromosome\n",
    "            continue\n",
    "\n",
    "    # Sort chromosome lengths based on chromosome number\n",
    "    sorted_chromosome_lengths = dict(sorted(chromosome_lengths.items(), key=lambda item: int(item[0])))\n",
    "    print(sorted_chromosome_lengths)\n",
    "    # Process each chromosome\n",
    "    for chrom, length in sorted_chromosome_lengths.items():\n",
    "        if chrom == \"24\" and \"24\" not in df['chr'].values:\n",
    "            continue\n",
    "\n",
    "        # Map chromosome \"23\" to \"X\" and \"24\" to \"Y\" for data lookup\n",
    "        lookup_chrom = \"23\" if chrom == \"23\" else (\"24\" if chrom == \"24\" else chrom)\n",
    "        \n",
    "        chrom_df = df[df['chr'] == str(lookup_chrom)]\n",
    "        sorted_chrom_df = chrom_df.sort_values(by='startpos')\n",
    "        \n",
    "        last_end = 0\n",
    "        print(sorted_chrom_df)\n",
    "        # If no data for this chromosome, add a single entry covering the entire chromosome\n",
    "        if sorted_chrom_df.empty:\n",
    "            record_id = increment_cnv()\n",
    "            info = f\"END={length};IMPRECISE\"\n",
    "            format_field = \"GT:CN\"\n",
    "            tumor_sample = \"1|1:1,1\"\n",
    "            normal_sample = \"0|0:1,1\"\n",
    "            vcf_records.append([chrom, 1, record_id, \".\", \"<CNV>\", \".\", \"PASS\", info, format_field, tumor_sample, normal_sample])\n",
    "        else:\n",
    "            for idx, row in sorted_chrom_df.iterrows():\n",
    "                start = row['startpos']\n",
    "                end = row['endpos']\n",
    "                nMajor = row['nMajor']\n",
    "                nMinor = row['nMinor']\n",
    "\n",
    "                # Fill gap before this segment if needed\n",
    "                if start > last_end + 1:\n",
    "                    record_id = increment_cnv()\n",
    "                    info = f\"END={start-1};IMPRECISE\"\n",
    "                    format_field = \"GT:CN\"\n",
    "                    tumor_sample = \"1|1:1,1\"\n",
    "                    normal_sample = \"0|0:1,1\"\n",
    "                    vcf_records.append([chrom, last_end + 1, record_id, \".\", \"<CNV>\", \".\", \"PASS\", info, format_field, tumor_sample, normal_sample])\n",
    "\n",
    "                # Add the segment from ASCAT data\n",
    "                record_id = increment_cnv()\n",
    "                info = f\"END={end};IMPRECISE\"\n",
    "                format_field = \"GT:CN\"\n",
    "                tumor_sample = f\"1|1:{nMajor},{nMinor}\"\n",
    "                normal_sample = \"0|0:1,1\"\n",
    "                vcf_records.append([chrom, start, record_id, \".\", \"<CNV>\", \".\", \"PASS\", info, format_field, tumor_sample, normal_sample])\n",
    "\n",
    "                last_end = end\n",
    "\n",
    "            # Fill gap after last segment if needed\n",
    "            if last_end < length:\n",
    "                record_id = increment_cnv()\n",
    "                info = f\"END={length};IMPRECISE\"\n",
    "                format_field = \"GT:CN\"\n",
    "                tumor_sample = \"1|1:1,1\"\n",
    "                normal_sample = \"0|0:1,1\"\n",
    "                vcf_records.append([chrom, last_end + 1, record_id, \".\", \"<CNV>\", \".\", \"PASS\", info, format_field, tumor_sample, normal_sample])\n",
    "\n",
    "    # Create the VCF DataFrame\n",
    "    vcf_df = pd.DataFrame(vcf_records, columns=[\"#CHROM\", \"POS\", \"ID\", \"REF\", \"ALT\", \"QUAL\", \"FILTER\", \"INFO\", \"FORMAT\", \"TUMOR\", \"NORMAL\"])\n",
    "    \n",
    "    # Ensure #CHROM and POS are int columns before sorting\n",
    "    vcf_df[\"#CHROM\"] = vcf_df[\"#CHROM\"].astype(int)\n",
    "    vcf_df[\"POS\"] = vcf_df[\"POS\"].astype(int)\n",
    "    \n",
    "    # Sort the VCF DataFrame by chromosome and position\n",
    "    vcf_df = vcf_df.sort_values(by=[\"#CHROM\", \"POS\"]).reset_index(drop=True)\n",
    "    \n",
    "    # Reassign CNV IDs in numerical ascending order\n",
    "    vcf_df[\"ID\"] = [\"cnv\" + str(i + 1) for i in range(len(vcf_df))]\n",
    "    \n",
    "    return vcf_df\n",
    "\n",
    "def read_strelka(input_file_path):\n",
    "    filtered_lines = []\n",
    "    with gzip.open(input_file_path, 'rt') as file:\n",
    "        for line in file:\n",
    "            if not line.startswith('##'):\n",
    "                filtered_lines.append(line)\n",
    "\n",
    "    filtered_content = ''.join(filtered_lines)\n",
    "    df_snv = pd.read_csv(StringIO(filtered_content), sep='\\t')\n",
    "    df_snv['#CHROM'] = df_snv['#CHROM'].apply(convert_chromosome)\n",
    "    return df_snv\n",
    "\n",
    "def get_position(input_string, search):\n",
    "    # Split the input string by ':'\n",
    "    split_string = input_string.split(':')\n",
    "    \n",
    "    # Find the position of 'AU'\n",
    "    try:\n",
    "        position = split_string.index(search)\n",
    "    except ValueError:\n",
    "        position = -1  # 'AU' not found in the string\n",
    "    \n",
    "    return position\n",
    "\n",
    "def get_variant_reads(row, type, alt):\n",
    "\n",
    "    AU_index = get_position(row['FORMAT'],'AU')\n",
    "    CU_index = get_position(row['FORMAT'],'CU')\n",
    "    GU_index = get_position(row['FORMAT'],'GU')\n",
    "    TU_index = get_position(row['FORMAT'],'TU')\n",
    "                \n",
    "    if alt == \"A\":\n",
    "        variant_reads = row[type].split(\":\")[AU_index].split(',')\n",
    "        variant_reads = [int(x) for x in variant_reads] \n",
    "        total_variant_reads = sum(variant_reads)  # Sum the integer values\n",
    "    elif alt == \"C\":\n",
    "        variant_reads = row[type].split(\":\")[CU_index].split(',')\n",
    "        variant_reads = [int(x) for x in variant_reads] \n",
    "        total_variant_reads = sum(variant_reads)  # Sum the integer values\n",
    "    elif alt == \"G\":\n",
    "        variant_reads = row[type].split(\":\")[GU_index].split(',')\n",
    "        variant_reads = [int(x) for x in variant_reads] \n",
    "        total_variant_reads = sum(variant_reads)  # Sum the integer values\n",
    "    elif alt == \"T\":\n",
    "        variant_reads = row[type].split(\":\")[TU_index].split(',')\n",
    "        variant_reads = [int(x) for x in variant_reads] \n",
    "        total_variant_reads = sum(variant_reads)  # Sum the integer values\n",
    "    else:\n",
    "        raise Exception(\"Not recognized nucleotide\")\n",
    "\n",
    "    indices = [AU_index, CU_index, GU_index, TU_index]\n",
    "    total_reads = []\n",
    "    \n",
    "    for index in indices:\n",
    "        total_reads += row['TUMOR'].split(\":\")[index].split(',')\n",
    "                \n",
    "    total_reads = [int(x) for x in total_reads]\n",
    "    total_reads = sum(total_reads)\n",
    "    \n",
    "    return total_variant_reads, total_reads\n",
    "\n",
    "\n",
    "def convert_strelka_snv_to_tusv_ext_df(strelka_df, ascat_df, option):\n",
    "    \"\"\"\n",
    "    option can be phased or unphased\n",
    "    \"\"\"\n",
    "    tusv_ext_rows = []\n",
    "    strelka_df = strelka_df[strelka_df[\"FILTER\"] == \"PASS\"]\n",
    "    strelka_df.reset_index(inplace=True)\n",
    "    for index, row in strelka_df.iterrows():\n",
    "        chrom = row['#CHROM']\n",
    "        pos = row['POS']\n",
    "        ref = row['REF']\n",
    "        alt = row['ALT']\n",
    "        if option == \"phased\":\n",
    "            raise Exception(\"Not implemented yet\")\n",
    "        elif option == \"unphased\":\n",
    "            data_types = [\"TUMOR\", \"NORMAL\"]\n",
    "            CNADJ_dict = {}\n",
    "            for type in data_types:  \n",
    "                total_variant_reads, total_reads = get_variant_reads(row, type, alt)\n",
    "                CN_tot = get_total_copy_number(ascat_df, chrom, pos)\n",
    "    \n",
    "                \n",
    "                CNADJ = (total_variant_reads)/(total_reads)*CN_tot\n",
    "                CNADJ = float(CNADJ)\n",
    "                CNADJ = format(CNADJ, '.2f')\n",
    "                CNADJ_dict[type] = CNADJ\n",
    "        else:\n",
    "            raise Exception(\"Unknown Option\")\n",
    "        qual = \".\"\n",
    "        filter_val = row[\"FILTER\"]\n",
    "        info = \".\"\n",
    "        variant_id = f\"snv{snv_count}\"\n",
    "        increment_snv()\n",
    "\n",
    "\n",
    "        format_field = 'GT:CNADJ'\n",
    "        tumor_data = \"1|1\" + \":\" + CNADJ_dict[\"TUMOR\"]\n",
    "        normal_data = \"0|0\" + \":\" + CNADJ_dict[\"NORMAL\"]\n",
    "        tusv_ext_rows.append([\n",
    "            chrom, pos, variant_id, ref, alt, qual, filter_val, info, format_field, tumor_data, normal_data\n",
    "        ])\n",
    "        \n",
    "    tusv_ext_df = pd.DataFrame(tusv_ext_rows, columns=[\n",
    "        '#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'TUMOR', 'NORMAL'\n",
    "    ])\n",
    "    return tusv_ext_df\n",
    "\n",
    "def read_manta_sv(input_file_path):\n",
    "    filtered_lines = []\n",
    "    with gzip.open(input_file_path, 'rt') as file:\n",
    "        for line in file:\n",
    "            if not line.startswith('##'):\n",
    "                filtered_lines.append(line)\n",
    "    filtered_content = ''.join(filtered_lines)\n",
    "    df_manta_sv = pd.read_csv(StringIO(filtered_content), sep='\\t')\n",
    "    df_manta_sv['#CHROM'] = df_manta_sv['#CHROM'].apply(convert_chromosome)\n",
    "    \n",
    "    return df_manta_sv\n",
    "\n",
    "\n",
    "\n",
    "def get_total_copy_number(df, chrom, pos):\n",
    "    \"\"\"\n",
    "    Gets the total copy number (major + minor) at a given chromosome and position.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing ASCAT data.\n",
    "    chrom (str or int): The chromosome number.\n",
    "    pos (int): The position on the chromosome.\n",
    "\n",
    "    Returns:\n",
    "    int or None: The total copy number at the given position, or None if the position is not covered.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame for the given chromosome\n",
    "    chr_df = df[df['chr'] == chrom]\n",
    "    \n",
    "    # Iterate over the rows to find the interval that contains the position\n",
    "    for _, row in chr_df.iterrows():\n",
    "        if row['startpos'] <= pos <= row['endpos']:\n",
    "            total_cn = row['nMajor'] + row['nMinor']\n",
    "            return total_cn\n",
    "    \n",
    "    # If no interval contains the position, return 2 assuming 2 normal alleles\n",
    "    return 2\n",
    "\n",
    "\n",
    "# Function to rename columns\n",
    "def rename_column(col_name):\n",
    "    last_split = col_name.split('-')[-1]\n",
    "    if last_split.startswith('T'):\n",
    "        return 'TUMOR'\n",
    "    elif last_split.startswith('N'):\n",
    "        return 'NORMAL'\n",
    "    return col_name\n",
    "# You may need to estimate CNAJ using CNVKit information tied to Manta output, and right hard conversion functions for DP and BDP\n",
    "\n",
    "\n",
    "def calculate_metrics(ascat_df, row):\n",
    "        # Ref then alt in the order list\n",
    "    data_columns = ['TUMOR', 'NORMAL']\n",
    "\n",
    "    for data in data_columns:\n",
    "        if row[\"FORMAT\"] == \"PR\":\n",
    "            PR = row[data]\n",
    "            \n",
    "            PR_ref = int(PR.split(\",\")[0])\n",
    "            PR_alt = int(PR.split(\",\")[1])\n",
    "            PR_tot = PR_ref + PR_alt\n",
    "            \n",
    "            SR_ref = 0\n",
    "            SR_alt = 0\n",
    "            SR_tot = 0\n",
    "        else:\n",
    "            try:\n",
    "        \n",
    "                PR = row[data].split(\":\")[0]\n",
    "                SR = row[data].split(\":\")[1]\n",
    "        \n",
    "                PR_ref = int(PR.split(\",\")[0])\n",
    "                PR_alt = int(PR.split(\",\")[1])\n",
    "                PR_tot = PR_ref + PR_alt\n",
    "        \n",
    "                \n",
    "                SR_ref = int(SR.split(\",\")[0])\n",
    "                SR_alt = int(SR.split(\",\")[1])\n",
    "                SR_tot = SR_ref + SR_alt\n",
    "    \n",
    "            except IndexError:\n",
    "                raise Exception(\"IndexError found\")\n",
    "\n",
    "        if data == 'TUMOR':\n",
    "            GT = \"1|1\"\n",
    "            CN_tot = get_total_copy_number(ascat_df, row['#CHROM'], row['POS'])\n",
    "            \n",
    "            CNADJ = (PR_alt + SR_alt)/(PR_tot + SR_tot)*CN_tot\n",
    "            CNADJ = float(CNADJ)\n",
    "            CNADJ_formatted = format(CNADJ, '.2f')\n",
    "\n",
    "            BDP = SR_alt\n",
    "            DP = SR_alt + PR_alt\n",
    "            variables = [GT, CNADJ_formatted, BDP, DP]\n",
    "            tumor_data = ':'.join(map(str, variables))\n",
    "        elif data == 'NORMAL':\n",
    "            GT = \"0|0\"\n",
    "            CN_tot = 2\n",
    "            CNADJ = (PR_ref + SR_ref)/(PR_tot + SR_tot)*CN_tot\n",
    "            CNADJ = float(CNADJ)\n",
    "            CNADJ_formatted = format(CNADJ, '.2f')\n",
    "            BDP = SR_ref\n",
    "            DP = SR_ref + PR_alt\n",
    "            variables = [GT, CNADJ_formatted, BDP, DP]\n",
    "            normal_data = ':'.join(map(str, variables))\n",
    "        else:\n",
    "            raise Exception(\"Unknown Datatype\")\n",
    "    return tumor_data, normal_data\n",
    "\n",
    "def rewrite_manta_results(df_manta_sv, ascat_df):\n",
    "\n",
    "    # Filter for SVs that pass all filters\n",
    "    # df_manta_sv = df_manta_sv[df_manta_sv['FILTER'] == \"PASS\"] # Removing this temporairly as minsomaticscore may just be a low clone issue.\n",
    "\n",
    "    \n",
    "    # Filter for BND types and paired breakpoints\n",
    "    bnd_df = df_manta_sv[df_manta_sv['INFO'].str.contains(\"SVTYPE=BND\")]\n",
    "\n",
    "    # Split the INFO column into a dictionary for easy access\n",
    "    bnd_df['INFO_DICT'] = bnd_df['INFO'].apply(lambda x: dict(item.split('=') for item in x.split(';') if '=' in item))\n",
    "\n",
    "    # Filter out unpaired BNDs\n",
    "    mate_ids = bnd_df['INFO_DICT'].apply(lambda x: x.get('MATEID', None))\n",
    "    paired_bnd_df = bnd_df[bnd_df['ID'].isin(mate_ids.values)]\n",
    "\n",
    "\n",
    "    # Prepare new VCF columns\n",
    "    vcf_columns = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'TUMOR', 'NORMAL']\n",
    "    vcf_df = pd.DataFrame(columns=vcf_columns)\n",
    "    \n",
    "    # Create a dictionary to store the paired rows\n",
    "    paired_rows = {}\n",
    "\n",
    "    # Renaming column heads for ease of access downstream to TUMOR and NORMAL\n",
    "    paired_bnd_df.rename(columns=lambda x: rename_column(x), inplace=True)\n",
    "    print(paired_bnd_df['FORMAT'].unique())\n",
    "    for index, row in paired_bnd_df.iterrows():\n",
    "        mate_id = row['INFO_DICT']['MATEID']\n",
    "        paired_rows[row['ID']] = row\n",
    "        if mate_id in paired_rows:\n",
    "\n",
    "\n",
    "            \n",
    "            mate_row = paired_rows[mate_id]\n",
    "\n",
    "\n",
    "            # Create the ALT field\n",
    "            alt = row[\"ALT\"]\n",
    "            alt = str(alt).replace('chr','')\n",
    "            alt = alt.replace(row['REF'],'')\n",
    "            alt = alt.replace('X','23')\n",
    "            #Recalculate ID here for row and mate_row\n",
    "            row_sv_ID = f\"sv{sv_count}\"\n",
    "            increment_sv()\n",
    "\n",
    "            mate_row_sv_ID = f\"sv{sv_count}\"\n",
    "            increment_sv()\n",
    "            \n",
    "            # Create the INFO field\n",
    "            info = f\"MATEID={mate_row_sv_ID};SVTYPE=BND\"\n",
    "\n",
    "            # Create the FORMAT fields \n",
    "            format_field = \"GT:CNADJ:BDP:DP\"\n",
    "\n",
    "\n",
    "            tumor_data, normal_data = calculate_metrics(ascat_df, row)\n",
    "\n",
    "\n",
    "            # Append the rows to the new DataFrame\n",
    "            vcf_df = vcf_df.append({\n",
    "                '#CHROM': row['#CHROM'], 'POS': row['POS'], 'ID': row_sv_ID, 'REF': '.',\n",
    "                'ALT': alt, 'QUAL': row['QUAL'], 'FILTER': row['FILTER'], 'INFO': info,\n",
    "                'FORMAT': format_field, 'TUMOR': tumor_data, 'NORMAL': normal_data\n",
    "            }, ignore_index=True)\n",
    "\n",
    "\n",
    "            # Create the ALT field\n",
    "            alt_mate = mate_row[\"ALT\"]\n",
    "            alt_mate = str(alt_mate).replace('chr','')\n",
    "            alt_mate = alt_mate.replace(mate_row['REF'],'')\n",
    "            alt_mate = alt_mate.replace('X','23')\n",
    "\n",
    "\n",
    "            info_mate = f\"MATEID={row_sv_ID};SVTYPE=BND\"\n",
    "\n",
    "\n",
    "            tumor_data, normal_data = calculate_metrics(ascat_df, mate_row)\n",
    "\n",
    "            \n",
    "            vcf_df = vcf_df.append({\n",
    "                '#CHROM': mate_row['#CHROM'], 'POS': mate_row['POS'], 'ID': mate_row_sv_ID, 'REF': '.',\n",
    "                'ALT': alt_mate, 'QUAL': mate_row['QUAL'], 'FILTER': mate_row['FILTER'], 'INFO': info_mate,\n",
    "                'FORMAT': format_field, 'TUMOR': tumor_data, 'NORMAL': normal_data\n",
    "            }, ignore_index=True)\n",
    "\n",
    "    return vcf_df\n",
    "\n",
    "# Claude provided functions for static ID assignment\n",
    "\n",
    "def collect_variants(frozen_samples, variant_calling_folder, reference_genome_path):\n",
    "    all_cnvs = []\n",
    "    all_svs = []\n",
    "    all_snvs = []\n",
    "\n",
    "    for sample_name in frozen_samples:\n",
    "        logging.info(f\"Collecting variants for {sample_name}\")\n",
    "        strelka_snv_path = os.path.join(variant_calling_folder, 'strelka', sample_name, f'{sample_name}.strelka.somatic_snvs.vcf.gz')\n",
    "        manta_sv_path = os.path.join(variant_calling_folder, 'manta', sample_name, f'{sample_name}.manta.somatic_sv.vcf.gz')\n",
    "        ascat_cnv_path = os.path.join(variant_calling_folder, 'ascat', sample_name, f'{sample_name}.cnvs.txt')\n",
    "\n",
    "        ascat_df = load_ascat_cnv(ascat_cnv_path)\n",
    "        cnv_df = convert_ascat_to_vcf_df(ascat_df, reference_genome_path)\n",
    "        cnv_df['sample'] = sample_name\n",
    "        all_cnvs.append(cnv_df)\n",
    "\n",
    "        df_manta_sv = read_manta_sv(manta_sv_path)\n",
    "        sv_df = rewrite_manta_results(df_manta_sv, ascat_df)\n",
    "        sv_df['sample'] = sample_name\n",
    "        all_svs.append(sv_df)\n",
    "\n",
    "        df_snv = read_strelka(strelka_snv_path)\n",
    "        snv_df = convert_strelka_snv_to_tusv_ext_df(df_snv, ascat_df, \"unphased\")\n",
    "        snv_df['sample'] = sample_name\n",
    "        all_snvs.append(snv_df)\n",
    "\n",
    "        logging.info(f\"Collected variants for {sample_name}: CNVs: {len(cnv_df)}, SVs: {len(sv_df)}, SNVs: {len(snv_df)}\")\n",
    "\n",
    "    return pd.concat(all_cnvs, ignore_index=True), pd.concat(all_svs, ignore_index=True), pd.concat(all_snvs, ignore_index=True)\n",
    "\n",
    "def deduplicate_and_assign_sv_ids(df):\n",
    "    # Extract MATEID from INFO column\n",
    "    df['MATEID'] = df['INFO'].str.extract(r'MATEID=([^;]+)')\n",
    "    \n",
    "    # Create a unique identifier for each SV pair\n",
    "    df['pair_id'] = df.apply(lambda row: '_'.join(sorted([row['ID'], row['MATEID']])), axis=1)\n",
    "    \n",
    "    # Group by relevant columns to identify unique SV pairs\n",
    "    group_cols = ['#CHROM', 'POS', 'ALT', 'pair_id']\n",
    "    df['group'] = df.groupby(group_cols).ngroup()\n",
    "    \n",
    "    # Assign new IDs\n",
    "    new_ids = {}\n",
    "    current_id = 1\n",
    "    for _, group in df.groupby('group'):\n",
    "        ids = group['ID'].tolist()\n",
    "        mate_ids = group['MATEID'].tolist()\n",
    "        \n",
    "        for id, mate_id in zip(ids, mate_ids):\n",
    "            if id not in new_ids:\n",
    "                new_ids[id] = f'sv{current_id}'\n",
    "                current_id += 1\n",
    "            if mate_id not in new_ids:\n",
    "                new_ids[mate_id] = f'sv{current_id}'\n",
    "                current_id += 1\n",
    "    \n",
    "    # Apply new IDs\n",
    "    df['new_ID'] = df['ID'].map(new_ids)\n",
    "    \n",
    "    # Update MATEID in INFO column\n",
    "    def update_mateid(row):\n",
    "        old_mateid = re.search(r'MATEID=([^;]+)', row['INFO']).group(1)\n",
    "        new_mateid = new_ids.get(old_mateid, old_mateid)  # Use old MATEID if not in new_ids\n",
    "        return re.sub(r'MATEID=[^;]+', f'MATEID={new_mateid}', row['INFO'])\n",
    "\n",
    "    df['INFO'] = df.apply(update_mateid, axis=1)\n",
    "    \n",
    "    # Replace old ID with new ID\n",
    "    df['ID'] = df['new_ID']\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    df = df.drop(columns=['MATEID', 'pair_id', 'group', 'new_ID'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def deduplicate_and_assign_ids(df, variant_type):\n",
    "    if variant_type == 'cnv':\n",
    "        group_cols = ['#CHROM', 'POS', 'END', 'CN']\n",
    "        df['END'] = df['INFO'].str.extract(r'END=(\\d+)').astype(float)\n",
    "        df['CN'] = df['TUMOR'].str.split(':').str[1]\n",
    "    elif variant_type == 'sv':\n",
    "        return deduplicate_and_assign_sv_ids(df)\n",
    "    elif variant_type == 'snv':\n",
    "        group_cols = ['#CHROM', 'POS', 'REF', 'ALT']\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown variant type: {variant_type}\")\n",
    "\n",
    "    if variant_type != 'sv':\n",
    "        # Group and assign new IDs\n",
    "        df['group'] = df.groupby(group_cols).ngroup()\n",
    "        df['ID'] = variant_type + (df['group'] + 1).astype(str)\n",
    "\n",
    "        # Clean up temporary columns\n",
    "        df = df.drop(columns=['group'])\n",
    "        if variant_type == 'cnv':\n",
    "            df = df.drop(columns=['END', 'CN'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def write_output_files(frozen_samples, variant_calling_folder, output_folder, cnv_df, sv_df, snv_df):\n",
    "    for sample_name in frozen_samples:\n",
    "        logging.info(f\"Writing output for {sample_name}\")\n",
    "        output_file_path = init_vcf(output_folder, sample_name)\n",
    "\n",
    "        # Filter variants for this sample\n",
    "        sample_cnv_df = cnv_df[cnv_df['sample'] == sample_name].copy()\n",
    "        sample_sv_df = sv_df[sv_df['sample'] == sample_name].copy()\n",
    "        sample_snv_df = snv_df[snv_df['sample'] == sample_name].copy()\n",
    "\n",
    "        # Remove the 'sample' column before writing\n",
    "        for df in [sample_cnv_df, sample_sv_df, sample_snv_df]:\n",
    "            if 'sample' in df.columns:\n",
    "                df.drop(columns=['sample'], inplace=True)\n",
    "\n",
    "        # Write variants to the output file\n",
    "        write_df_to_vcf(sample_cnv_df, output_file_path)\n",
    "        write_df_to_vcf(sample_sv_df, output_file_path)\n",
    "        write_df_to_vcf(sample_snv_df, output_file_path)\n",
    "\n",
    "        logging.info(f\"Finished writing output for {sample_name}\")\n",
    "        logging.info(f\"CNVs: {len(sample_cnv_df)}, SVs: {len(sample_sv_df)}, SNVs: {len(sample_snv_df)}\")\n",
    "        \n",
    "def create_pseudo_normal_vcf(output_folder, reference_genome_path):\n",
    "    \"\"\"\n",
    "    Creates a pseudo-normal VCF file where each chromosome has a copy number of 1\n",
    "    for both major and minor alleles, with no segmentation, structural variations,\n",
    "    or single nucleotide variants.\n",
    "    \n",
    "    Args:\n",
    "    output_folder (str): Path to the output folder where the VCF will be saved.\n",
    "    reference_genome_path (str): Path to the reference genome FASTA file.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Path to the created pseudo-normal VCF file and a set of used CNV IDs.\n",
    "    \"\"\"\n",
    "    output_file_path = os.path.join(output_folder, 'pseudo_normal.vcf')\n",
    "    used_ids = set()\n",
    "    \n",
    "    # Parse the reference genome file to get chromosome lengths\n",
    "    chromosome_lengths = {}\n",
    "    for record in SeqIO.parse(reference_genome_path, \"fasta\"):\n",
    "        if record.id.startswith(\"NC_0000\"):\n",
    "            chrom = record.id.split('.')[0].replace(\"NC_0000\", \"\")\n",
    "            chrom = str(int(chrom))  # Remove leading zeros\n",
    "            chromosome_lengths[chrom] = len(record.seq)\n",
    "    \n",
    "    # Sort chromosome lengths based on chromosome number\n",
    "    sorted_chromosome_lengths = dict(sorted(chromosome_lengths.items(), key=lambda item: int(item[0])))\n",
    "    \n",
    "    with open(output_file_path, 'w') as file:\n",
    "        # Write VCF header\n",
    "        file.write('##fileformat=VCFv4.2\\n')\n",
    "        file.write('##fileDate=' + datetime.now().strftime('%Y%m%d') + '\\n')\n",
    "        file.write('##source=pseudo_normal_generator\\n')\n",
    "        file.write('##reference=' + reference_genome_path + '\\n')\n",
    "        file.write('##INFO=<ID=END,Number=1,Type=Integer,Description=\"End position of the variant described in this record\">\\n')\n",
    "        file.write('##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\\n')\n",
    "        file.write('##FORMAT=<ID=CN,Number=2,Type=Integer,Description=\"Copy number genotype for imprecise events\">\\n')\n",
    "        file.write('#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\\tNORMAL\\n')\n",
    "        \n",
    "        # Write entries for each chromosome\n",
    "        for chrom, length in sorted_chromosome_lengths.items():\n",
    "            if chrom == \"24\":  # Skip Y chromosome\n",
    "                continue\n",
    "            \n",
    "            cnv_id = f'cnv{chrom}'\n",
    "            used_ids.add(cnv_id)\n",
    "            file.write(f'{chrom}\\t1\\t{cnv_id}\\t.\\t<CNV>\\t.\\tPASS\\t')\n",
    "            file.write(f'END={length};IMPRECISE\\tGT:CN\\t0|0:1,1\\n')\n",
    "    \n",
    "    return output_file_path, used_ids\n",
    "\n",
    "def assign_consistent_ids(cnv_df, sv_df, snv_df, used_ids):\n",
    "    \"\"\"\n",
    "    Assigns consistent IDs across all variant types, taking into account\n",
    "    the IDs already used in the pseudo-normal VCF.\n",
    "    \n",
    "    Args:\n",
    "    cnv_df (pd.DataFrame): DataFrame containing CNV data.\n",
    "    sv_df (pd.DataFrame): DataFrame containing SV data.\n",
    "    snv_df (pd.DataFrame): DataFrame containing SNV data.\n",
    "    used_ids (set): Set of IDs already used in the pseudo-normal VCF.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Updated DataFrames for CNV, SV, and SNV data.\n",
    "    \"\"\"\n",
    "    # Function to get the next available ID\n",
    "    def get_next_id(prefix, current_id):\n",
    "        while f\"{prefix}{current_id}\" in used_ids:\n",
    "            current_id += 1\n",
    "        return current_id\n",
    "\n",
    "    # Assign CNV IDs\n",
    "    cnv_current_id = 1\n",
    "    cnv_df = cnv_df.sort_values(['#CHROM', 'POS'])\n",
    "    for idx, row in cnv_df.iterrows():\n",
    "        cnv_id = f\"cnv{row['#CHROM']}\" if row['POS'] == 1 and row['INFO'].endswith(f\"END={chromosome_lengths[row['#CHROM']]}\") else f\"cnv{get_next_id('cnv', cnv_current_id)}\"\n",
    "        cnv_df.at[idx, 'ID'] = cnv_id\n",
    "        used_ids.add(cnv_id)\n",
    "        cnv_current_id = int(cnv_id[3:]) + 1\n",
    "\n",
    "    # Assign SV IDs\n",
    "    sv_current_id = 1\n",
    "    for idx, row in sv_df.iterrows():\n",
    "        sv_id = f\"sv{get_next_id('sv', sv_current_id)}\"\n",
    "        sv_df.at[idx, 'ID'] = sv_id\n",
    "        used_ids.add(sv_id)\n",
    "        sv_current_id += 1\n",
    "\n",
    "    # Assign SNV IDs\n",
    "    snv_current_id = 1\n",
    "    for idx, row in snv_df.iterrows():\n",
    "        snv_id = f\"snv{get_next_id('snv', snv_current_id)}\"\n",
    "        snv_df.at[idx, 'ID'] = snv_id\n",
    "        used_ids.add(snv_id)\n",
    "        snv_current_id += 1\n",
    "\n",
    "    return cnv_df, sv_df, snv_df\n",
    "    \n",
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    variant_calling_folder = '/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/TUSV-ext/AFEC_WES_results/variant_calling/'\n",
    "    output_folder = '/bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/TUSV-ext/AFEC_compiled_input_wSVs/'\n",
    "    frozen_samples = ['AUR-AFEC-TTM1_vs_AUR-AFEC-NT1', 'AUR-AFEC-TTM3_vs_AUR-AFEC-NT1', 'AUR-AFEC-TTM4_vs_AUR-AFEC-NT1', 'AUR-AFEC-TTM5_vs_AUR-AFEC-NT1', 'AUR-AFEC-TTM6_vs_AUR-AFEC-NT1', 'AUR-AFEC-TTP2_vs_AUR-AFEC-NT1']\n",
    "    reference_genome_path = \"/bgfs/alee/LO_LAB/General/References/GCF_GRCh38/GCF_000001405.40_GRCh38.p14_genomic.fna\"\n",
    "\n",
    "    try:\n",
    "        # Create pseudo-normal VCF and get used IDs\n",
    "        pseudo_normal_vcf_path, used_ids = create_pseudo_normal_vcf(output_folder, reference_genome_path)\n",
    "        logging.info(f\"Created pseudo-normal VCF at: {pseudo_normal_vcf_path}\")\n",
    "\n",
    "        # Collect all variants\n",
    "        cnv_df, sv_df, snv_df = collect_variants(frozen_samples, variant_calling_folder, reference_genome_path)\n",
    "\n",
    "        # Log DataFrame shapes and column names\n",
    "        for name, df in [('CNV', cnv_df), ('SV', sv_df), ('SNV', snv_df)]:\n",
    "            logging.info(f\"{name} DataFrame shape: {df.shape}\")\n",
    "            logging.info(f\"{name} DataFrame columns: {df.columns.tolist()}\")\n",
    "            logging.info(f\"{name} sample distribution: {df['sample'].value_counts().to_dict()}\")\n",
    "\n",
    "        # Assign consistent IDs\n",
    "        cnv_df, sv_df, snv_df = assign_consistent_ids(cnv_df, sv_df, snv_df, used_ids)\n",
    "\n",
    "        # Write output files\n",
    "        write_output_files(frozen_samples, variant_calling_folder, output_folder, cnv_df, sv_df, snv_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {str(e)}\", exc_info=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861ffe0-598a-4a04-9ce4-b389343f9625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d651b20-a8d3-4715-a74d-0672ae4e5922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb60d0-0003-407e-b7d9-01e544c05eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b19af-48b6-44df-93ca-17ff9170873c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e5668-b0f5-4ddf-aa25-2db8586684ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f9386-5616-4fcd-b384-f3a39a03a1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TUSV-ext",
   "language": "python",
   "name": "tusv_ext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
